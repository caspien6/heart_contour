{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import png\n",
    "import pydicom\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "import transform_classes\n",
    "\n",
    "from roi import RoiLearn\n",
    "from roi_dataset import RoiDataset\n",
    "from preprocessor import Preprocessor\n",
    "\n",
    "import preprocess_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(n_inp, n_hidden)\n",
    "        self.decoder = nn.Linear(n_hidden, n_inp)\n",
    "        self.n_inp = n_inp\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = F.sigmoid(self.encoder(x))\n",
    "        decoded = F.sigmoid(self.decoder(encoded))\n",
    "        return encoded, decoded\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    '''\n",
    "    args:\n",
    "        2 tensors `p` and `q`\n",
    "    returns:\n",
    "        kl divergence between the softmax of `p` and `q`\n",
    "    '''\n",
    "    p = F.softmax(p)\n",
    "    q = F.softmax(q)\n",
    "\n",
    "    s1 = torch.sum(p * torch.log(p / q))\n",
    "    s2 = torch.sum((1 - p) * torch.log((1 - p) / (1 - q)))\n",
    "    return s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import png\n",
    "import pydicom\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch.nn.functional as F\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class RoiLearn:\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(12)\n",
    "        self.conv1 = nn.Conv2d(1,100, (11,11))\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.avgpool = nn.AvgPool2d(6)\n",
    "        self.flatten = Flatten()\n",
    "        self.full = nn.Linear(8100,1024)\n",
    "        #self.encoder = nn.Linear(121,100)\n",
    "        #self.decoder = nn.Linear(100,121)\n",
    "          \n",
    "    # Autoencoder architecture\n",
    "    def build_ae(self):\n",
    "        self.autoencoder = Autoencoder(121,100)\n",
    "        self.autoencoder = self.autoencoder.double()\n",
    "        \n",
    "    # Autoencoder W2 and b2 to the original model conv1 layer features and biases.\n",
    "    # From the parameters list - index 0 is the weights\n",
    "    #                          - index 1 is the biases\n",
    "    def ae_weights2model_feature_set(self):\n",
    "        \n",
    "        w2 = list(self.encoder.parameters())\n",
    "        \n",
    "        b2 = w2[1].detach().numpy()\n",
    "        # weights shape here (100,121)\n",
    "        w2 = np.expand_dims(w2[0].detach().numpy().reshape((100,11,11)), axis = 1)\n",
    "        # weights shape (100,1,11,11)\n",
    "        \n",
    "        conv1_features = list(self.conv1.parameters())\n",
    "        conv1_features[0] = torch.nn.Parameter(torch.from_numpy(w2))\n",
    "        conv1_features[1] = torch.nn.Parameter(torch.from_numpy(b2))\n",
    "        conv1_features[0].requires_grad=False\n",
    "        conv1_features[1].requires_grad=False\n",
    "        \n",
    "    # Rho - sparsity penalty pj = p    \n",
    "    def learn_ae(self, dataset_loader, optimizer,criterion, ep = 1, lr = 0.01, BETA = 3, RHO = 0.1):\n",
    "        rho = torch.FloatTensor([[RHO for _ in range(self.autoencoder.n_hidden)] for _ in range(dataset_loader.batch_size)]).double()\n",
    "        crit2 = nn.KLDivLoss(size_average=False)\n",
    "        for epoch in range(ep):\n",
    "            for i_batch, sample_batched in enumerate(dataset_loader):\n",
    "                #print(i_batch, sample_batched['image'].size(),sample_batched['mask'].size())\n",
    "                #print(sample_batched['image'].shape)\n",
    "                encoded, decoded = self.autoencoder(sample_batched['image'])\n",
    "                first_loss = criterion(sample_batched['image'],decoded)\n",
    "                sparsity_loss = crit2(rho, encoded)\n",
    "                #MSE_loss.view(1, -1).sum(1)\n",
    "                #MSE_loss = MSE_loss.view(1, -1).sum(1) / dataset_loader.batch_size\n",
    "                \n",
    "                #y_pred = self.autoencoder(sample_batched['image'])\n",
    "                #rho_hat = torch.sum(encoded, dim=0, keepdim=True) / dataset_loader.batch_size\n",
    "                #sparsity_penalty = BETA * F.kl_div( rho,rho_hat)\n",
    "                print(sparsity_loss)\n",
    "                loss = first_loss + BETA*sparsity_loss\n",
    "                \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print('epoch: ', epoch,' loss: ', loss.item())\n",
    "        \n",
    "                \n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model = nn.Sequential(self.conv1,\n",
    "                            self.avgpool,\n",
    "                            self.softmax,\n",
    "                            self.flatten,\n",
    "                            self.full,\n",
    "                            self.softmax\n",
    "                            )\n",
    "        self.model = self.model.double()\n",
    "    \n",
    "    def propagate_from_dataLoader(self,dl):\n",
    "        for i_batch, sample_batched in enumerate(dl):\n",
    "            print(self.model(sample_batched[0]))\n",
    "        \n",
    "    def propagate(self):\n",
    "        return self.model(self.x)\n",
    "    \n",
    "    def save_image( self,npdata, outfilename ) :\n",
    "        img = Image.fromarray( np.asarray( np.clip(npdata,0,255), dtype=\"uint8\"), \"L\" )\n",
    "        img.save( outfilename )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicom files were read in!\n",
      "Con files were read in!\n",
      "Dicom files were read in!\n",
      "Con files were read in!\n",
      "Dicom files were read in!\n",
      "Con files were read in!\n",
      "Dicom files were read in!\n",
      "Con files were read in!\n"
     ]
    }
   ],
   "source": [
    "# if we don't have the .csv file\n",
    "preprocess_img.write_all_rectangle2file('O:\\\\ProgrammingSoftwares\\\\anaconda_projects\\\\heart_contour\\\\sa_all_1\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-302.4361, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-304.0619, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-306.4438, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-303.4931, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-304.0738, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-304.5660, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-306.3905, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-307.1995, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-306.6145, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-305.4734, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-308.3309, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-306.5888, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-305.7754, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-309.7013, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-309.6545, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-307.4005, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-306.5646, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-307.6495, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-307.3258, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-307.7103, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-308.1912, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-309.1974, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.7960, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.0194, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-309.9953, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.3308, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-308.9802, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.1120, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.7781, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.4410, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.1620, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-311.1465, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.9848, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-309.0002, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-311.0112, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.0313, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.9651, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.2261, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-311.6719, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.2959, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.1171, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-311.7378, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.4978, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-311.4268, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.9877, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.4161, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.0198, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-311.7933, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-311.1812, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.0468, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-310.4636, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.5972, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.9885, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.7304, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.0386, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.2570, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.1601, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.3640, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.0073, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.5362, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.1362, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.4258, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.5590, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.3653, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.9925, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.7153, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.7140, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.5543, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.8839, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.6571, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.5366, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.8907, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.8925, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.9643, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.1090, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.6773, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-312.9037, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.0770, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.1815, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.1378, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.6572, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.0070, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.2128, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.7632, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.6778, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.0525, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.0568, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.8798, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.6609, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-314.5893, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-313.5251, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.5996, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.6292, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.0265, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.0724, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.5562, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.2128, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.1897, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.8859, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.4208, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.8001, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.8370, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.8909, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.9602, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.4016, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.6762, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.1134, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.9598, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.3896, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.4279, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.1072, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.1237, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.5203, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.2880, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.1908, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.1044, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.9983, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.1262, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.6671, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.5675, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.7950, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.2461, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-315.7259, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.9494, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.5760, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  0  loss:  -97.91801117078433\n",
      "tensor(-317.5504, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.0395, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.9190, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9427, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.2848, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.5659, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.7595, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.8420, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.0736, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.8739, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.8479, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-319.4951, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.3405, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.3658, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.5754, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.8458, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.5928, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.5735, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.6623, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.7681, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.1903, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.8335, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.4497, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9635, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9003, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.1489, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.3140, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.6018, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.7130, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.4569, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.4312, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5131, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.6608, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.8837, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.0005, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.9755, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.6748, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.7428, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-317.5660, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.5754, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9128, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.7874, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.3990, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.3926, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.7654, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.6478, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5470, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.7887, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9350, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.8677, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.8175, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.6971, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.2118, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.0970, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.3176, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.4575, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7067, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.2504, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.0641, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.7768, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.0925, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.8462, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.1825, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.7870, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.0475, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6372, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.7855, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.7201, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.9607, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0790, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.4730, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6380, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.4942, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.8955, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2691, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8687, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9638, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.3657, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6821, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1790, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6165, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2013, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3918, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5754, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6163, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1534, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.9534, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.8891, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2421, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7135, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0157, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5265, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2958, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5450, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5343, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3490, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8729, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5140, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6375, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1242, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6264, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0875, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5371, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.4674, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.4008, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1105, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0852, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6165, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3882, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6622, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2948, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9663, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.3971, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7593, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2751, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0041, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2953, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0008, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.8482, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1548, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7978, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.2488, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8680, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3392, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6178, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  1  loss:  -117.23094681924215\n",
      "tensor(-321.1966, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2657, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6217, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1550, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1428, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0527, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3192, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6562, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2195, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1715, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8440, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7827, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7258, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8067, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4246, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5608, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-322.3799, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1801, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3388, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5626, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1229, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3973, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3450, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8967, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5705, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7734, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3542, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3346, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3847, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5423, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2743, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6146, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5983, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4983, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6505, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7791, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1802, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6712, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8748, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6237, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0536, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3293, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9059, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1043, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4704, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0651, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7290, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5963, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5339, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6998, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3396, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2939, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5118, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5724, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8309, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7237, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2313, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3818, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5641, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8818, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3751, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5774, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9577, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9813, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8754, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5105, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0551, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1215, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2058, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0922, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5314, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5196, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0221, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8275, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0563, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5110, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6473, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0098, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0446, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1541, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5458, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1817, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5114, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2085, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0220, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4978, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0306, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0811, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7863, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5028, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7614, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9679, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8809, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0445, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5571, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5717, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6688, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1158, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9786, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6720, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9668, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1464, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5864, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4868, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3145, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9235, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2235, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5960, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6802, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8136, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3342, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1432, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6991, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6123, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0904, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8387, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9853, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5989, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0780, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5643, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8347, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8857, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0728, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2849, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7305, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  2  loss:  -110.2876960119595\n",
      "tensor(-323.4471, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8857, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3506, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5370, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9478, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7430, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4031, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0566, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7185, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7206, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6332, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6864, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9879, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8555, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6437, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2372, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9084, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3948, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-323.7402, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5641, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3521, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9638, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3325, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9303, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5418, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4448, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0804, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5278, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4025, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8947, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0913, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8563, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9159, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3135, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1081, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9363, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9844, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0541, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8418, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8523, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8215, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7163, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1287, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8590, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1412, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8587, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1087, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6182, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8253, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3589, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5636, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8893, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6467, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8576, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2152, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5669, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9210, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6337, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1853, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3321, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0932, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0520, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3332, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7985, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3072, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3358, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8407, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1084, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8015, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8603, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8098, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6505, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9775, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2992, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0267, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6075, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0770, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1513, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8997, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6331, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9992, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2458, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3733, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1765, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3984, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2906, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5880, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5931, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8319, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0201, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0567, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1155, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6927, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3619, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0336, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4411, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9639, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2034, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1726, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0513, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3110, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3667, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5583, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8305, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2611, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4559, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1171, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9404, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8602, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3993, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8164, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2323, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4426, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2902, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2863, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0821, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2598, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9320, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5144, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1128, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3465, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3811, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1864, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4733, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9693, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  3  loss:  -230.49263782794867\n",
      "tensor(-324.2761, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8136, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4628, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8811, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3155, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6836, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4539, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2392, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9852, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7595, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3116, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5852, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1127, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8513, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7322, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9696, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2321, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3221, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2256, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0044, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4763, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1804, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3992, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1958, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0941, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-323.7924, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8524, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6646, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0712, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3159, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5614, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1272, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9973, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2473, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4817, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3790, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9736, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3961, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1972, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3902, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7392, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0020, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4174, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4168, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4294, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1348, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3639, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3948, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4831, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3347, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5997, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3101, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3079, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3490, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1185, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9545, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9817, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0257, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3991, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4607, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2842, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4269, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4598, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8561, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0788, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2651, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0558, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3256, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3492, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7131, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4017, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0875, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9019, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1413, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3475, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2356, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6076, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3509, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3276, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4276, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5400, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4551, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3652, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0163, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9770, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2630, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5043, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0539, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2393, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3881, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2060, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8382, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1406, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3265, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7566, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1953, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0766, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1170, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2242, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1654, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4024, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1169, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0395, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7264, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1343, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6673, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2436, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1127, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3207, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8266, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5430, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2191, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3208, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6055, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6470, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5886, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3626, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4158, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9589, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3650, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1919, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0275, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5657, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1717, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4031, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  4  loss:  -9.327693421636354\n",
      "tensor(-323.8309, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2916, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6556, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9930, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8270, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2159, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0493, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3936, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0563, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2674, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7421, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7952, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0856, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5367, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0142, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7789, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1111, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3832, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1963, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1201, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3108, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8259, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5195, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3063, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2897, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2596, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3485, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2988, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9899, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-324.6710, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4102, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7993, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4669, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8408, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5704, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0560, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1256, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7932, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9793, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1625, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2591, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1595, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2651, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2561, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3787, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1366, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1479, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5241, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2983, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3954, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6919, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4324, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1534, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4258, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2316, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1085, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5254, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3212, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5954, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4127, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1975, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0440, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4079, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3538, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3391, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5299, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9007, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3895, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.8310, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8525, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2718, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2390, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4613, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2591, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2645, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9467, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0368, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1973, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7441, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3385, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9474, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5033, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1701, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3030, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6653, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9782, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6133, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2745, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4533, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0865, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9333, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9455, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9471, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2190, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3402, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2693, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6812, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8681, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1535, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4771, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2601, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5118, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6872, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0902, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.8160, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3565, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3780, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9439, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6074, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1143, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5933, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2483, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4110, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8616, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5861, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6713, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5288, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1912, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2325, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3938, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0690, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5653, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4733, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3157, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2372, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  5  loss:  -18.45816722192683\n",
      "tensor(-324.2579, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2790, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0786, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0843, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8008, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8291, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2734, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0490, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7692, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6298, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9784, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2697, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3196, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2977, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7747, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9144, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3726, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9659, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8196, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1030, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8289, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4145, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0690, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3228, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3010, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6074, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8657, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0339, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8596, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3005, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2667, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6382, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3176, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5157, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1402, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2506, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5169, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2963, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-324.0128, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4125, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1939, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5194, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1864, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5220, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3491, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1895, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4621, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0490, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1803, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3043, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4400, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4309, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6031, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9738, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3651, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0018, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5837, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2169, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3456, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0531, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2991, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5944, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8780, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8067, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4826, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8545, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1476, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2241, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1052, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8579, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3418, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3177, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4209, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2845, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9735, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3315, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1751, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9924, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6341, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2096, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.8188, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4421, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2131, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0405, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2819, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9313, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2450, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2605, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2453, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2719, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5202, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4280, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5959, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0696, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0379, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7071, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1666, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7446, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8713, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8428, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8066, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6614, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7899, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6554, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3783, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0501, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8494, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1673, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9358, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4650, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4336, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0896, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2956, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6977, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6652, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9861, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7441, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2445, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9474, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1894, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8516, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3414, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2740, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5280, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7962, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  6  loss:  -109.80294923158237\n",
      "tensor(-324.3421, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7180, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1441, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6393, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2450, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1232, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1274, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5207, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9976, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9990, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6504, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1212, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8339, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0928, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3560, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7860, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3146, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5108, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2090, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0882, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9855, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3372, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2039, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.8176, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0950, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9615, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5921, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5449, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0563, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7121, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4708, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5026, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6323, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7828, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3664, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6116, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4563, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0208, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8940, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2048, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8464, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8897, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0106, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8930, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-324.1542, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4339, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4628, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2316, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9059, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2870, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1464, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5489, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5251, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9390, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3981, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9729, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2075, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6702, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0357, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6286, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5603, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1698, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7720, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4484, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9876, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6129, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0795, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3462, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0095, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6846, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9185, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7325, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4183, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6995, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8208, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0006, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4751, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2165, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7663, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9926, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2580, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0206, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2571, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1600, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2386, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4633, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2203, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0218, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7767, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1824, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.6665, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5142, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2317, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7462, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1359, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5796, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1901, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8531, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4210, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7526, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1951, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7515, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4018, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4770, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3415, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6873, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3619, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2213, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6738, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9666, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2379, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7336, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3446, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9779, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0168, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4804, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6488, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2238, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2801, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5726, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0788, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2378, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4898, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2630, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3378, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  7  loss:  -127.43079590755633\n",
      "tensor(-322.9436, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1408, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8663, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8715, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2213, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5137, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1657, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9425, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2399, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8695, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4126, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8169, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1932, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6773, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5778, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.5100, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9189, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8303, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1988, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6285, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7692, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1803, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4282, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0872, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1426, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6537, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3661, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4319, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5516, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8437, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7757, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1281, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8107, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8237, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6402, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9839, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4121, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0234, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.4595, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9342, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1333, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0959, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5399, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5577, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6314, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.2775, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0877, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7488, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2243, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6462, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8785, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0572, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.2252, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0159, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3561, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6256, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.4233, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2658, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-322.6796, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0707, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7968, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7327, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.7121, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9271, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2302, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8626, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0400, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7477, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.1461, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6014, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7184, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4173, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0196, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3615, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9872, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3413, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5463, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4459, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5102, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0407, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2682, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6191, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3227, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.9556, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2170, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6589, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5138, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9652, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0921, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5071, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9369, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9308, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0802, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2443, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.3077, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8159, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4867, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6789, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8633, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6110, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0858, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8158, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0337, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8715, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4659, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2803, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3299, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6693, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.5014, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.3982, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.5272, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3972, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6513, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6514, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0013, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.7252, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1454, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0719, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9231, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.3920, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5470, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7971, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5236, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7908, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5152, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  8  loss:  -37.53657199089059\n",
      "tensor(-320.6050, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0869, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9878, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8041, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9102, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7424, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9438, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2720, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.4663, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8342, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.3222, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.7222, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1520, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2738, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.2539, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9102, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8605, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7822, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.6218, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9431, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3911, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6827, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1823, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8215, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.5448, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.7678, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9195, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6266, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2248, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0490, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6710, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3675, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.0424, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5095, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.1717, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6257, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.3012, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.3971, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9562, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5504, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4445, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.9499, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1566, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0591, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6259, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.0288, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0790, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2442, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8850, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.6394, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8575, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9941, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.3637, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0892, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.3125, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0165, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.9615, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0097, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2048, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.5163, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1597, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5323, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1388, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.3053, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.7370, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2485, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8601, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0068, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9833, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6406, dtype=torch.float64, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-322.9410, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1495, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1767, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7685, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.8958, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1154, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0424, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7334, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.9113, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0759, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0905, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.2297, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.0322, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.4253, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8807, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.2567, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.4540, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.1795, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9179, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6677, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2901, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8802, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.6152, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.8030, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7703, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.1963, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.3622, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2170, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.5112, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.9493, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8578, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.0679, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-319.9642, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.2362, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.1573, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.7875, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.7314, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1437, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.4984, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.7048, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0493, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.6513, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.2284, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-316.7135, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-321.9093, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.4473, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-324.4845, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.3645, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.0004, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.8101, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6132, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-323.6460, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-320.2044, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-318.7606, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "tensor(-322.1533, dtype=torch.float64, grad_fn=<KlDivBackward>)\n",
      "epoch:  9  loss:  -141.9679129978873\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'O:/ProgrammingSoftwares/anaconda_projects/heart_contour/sa_all_1/rectangle.csv'\n",
    "\n",
    "compose3 = Compose([transform_classes.GetRandomPatch(),transform_classes.StandardScale2(),transform_classes.ToTensor()])\n",
    "\n",
    "ds2 = RoiDataset(csv_file, compose3)\n",
    "roi = RoiLearn()\n",
    "roi.build_ae()\n",
    "\n",
    "crit = torch.nn.MSELoss(size_average = True)\n",
    "opt = torch.optim.Adam(roi.autoencoder.parameters(),  weight_decay = 0.0001 )\n",
    "\n",
    "# Random 1000 sample\n",
    "weighted_rnd_sample = torch.utils.data.WeightedRandomSampler([float(1/len(ds2)) for i in range(len(ds2))], 1000, replacement=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(ds2,batch_size=8, num_workers=0, sampler=weighted_rnd_sample)\n",
    "\n",
    "roi.learn_ae(dataset_loader, optimizer = opt, criterion = crit,  ep = 10)\n",
    "\n",
    "#roi.ae_weights2model_feature_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ezek a tensorok a sparsity penalty értékei batch-enként."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0278, -0.0151, -0.0972,  ...,  0.1100,  0.1107,  0.0876],\n",
       "        [ 0.0771,  0.0222,  0.0840,  ..., -0.0344, -0.0756,  0.0668],\n",
       "        [-0.0089, -0.0514,  0.0511,  ...,  0.0566, -0.0500, -0.1025],\n",
       "        ...,\n",
       "        [-0.0133,  0.0592, -0.0483,  ..., -0.0714, -0.0549, -0.1544],\n",
       "        [ 0.0342,  0.0797,  0.0925,  ..., -0.0649,  0.0245,  0.0406],\n",
       "        [ 0.0799,  0.0340, -0.0507,  ...,  0.0252,  0.1131,  0.0358]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi.autoencoder.encoder.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torchvision.transforms import Compose\n",
    "import transform_classes\n",
    "\n",
    "csv_file = 'O:/ProgrammingSoftwares/anaconda_projects/heart_contour/sa_all_1/rectangle.csv'\n",
    "compose1 = Compose([transform_classes.ReScale64(),transform_classes.StandardScale(),transform_classes.ToTensor()])\n",
    "compose2 = Compose([transform_classes.ReScale32(),transform_classes.ToTensor()])\n",
    "ds = RoiDataset(csv_file, compose1, compose2)\n",
    "\n",
    "roi = RoiLearn()\n",
    "roi.build_model()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(roi.model.parameters(), lr=0.1)\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(ds,batch_size=32, shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
