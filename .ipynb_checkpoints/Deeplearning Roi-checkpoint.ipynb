{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(n_h, n_out),\n",
    "                     nn.Sigmoid())\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "for epoch in range(50):\n",
    "    # Forward Propagation\n",
    "    y_pred = model(x)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_image('./root/cleaned_data/img_0_22.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import png\n",
    "import pydicom\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from roi import RoiLearn\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roii = RoiLearn()\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "dataLoader = preprocessor.create_datasetLoaderDCM('./root')\n",
    "preprocessor.show_some_loadedData()\n",
    "\n",
    "roii.build_model()\n",
    "\n",
    "roii.propagate_from_dataLoader(dataLoader)\n",
    "#y_pred = roi.propagate().detach().numpy()\n",
    "#save_image(y_pred[0,0,:,:]*255, 'pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from dicom_reader import DCMreader\n",
    "\n",
    "class RoiDataset(Dataset):\n",
    "    \"\"\"Roi dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with contour data.\n",
    "            root_dir (string): Directory for .dcm images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        'height is  (y length) width is  (x length)'\n",
    "        self.contour_data = pd.read_csv(csv_file,sep=';', names=('slice', 'frame', 'xmin', 'ymin', 'height','width' ))\n",
    "        self.dcm_images = DCMreader(root_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.contour_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cont = ds.contour_data.iloc[idx]\n",
    "        sl = int(cont['slice'])\n",
    "        fr = int(cont['frame'])\n",
    "        \n",
    "        mask = np.zeros((224,224))\n",
    "        mask[ int(cont['ymin']): int(cont['ymin']) + int(cont['height']),int(cont['xmin']): int(cont['xmin']) + int(cont['width'])] = 1\n",
    "        image = self.dcm_images.get_image(sl,fr)\n",
    "        \n",
    "        sample = {'image': image, 'mask': mask}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "        if self.target_transform:\n",
    "            sample['mask'] = self.target_transform(sample['mask'])\n",
    "\n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "class ReScale64(object):\n",
    "    \"\"\"Scale down ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data = resize(data, (64, 64))\n",
    "        return data\n",
    "\n",
    "\n",
    "class ReScale32(object):\n",
    "    \"\"\"Scale down ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data = resize(data, (32, 32))\n",
    "        data = np.reshape(data, (1024))\n",
    "        return data\n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return torch.from_numpy(data)\n",
    "    \n",
    "class StandardScale(object):\n",
    "    \"\"\"Standard scale ndarrays.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        scaler = StandardScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "        \n",
    "        # add color axis because\n",
    "        # numpy image: H x W\n",
    "        # torch image: C X H X W\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "csv_file = 'C:/Users/Ede/Documents/Iskola/onw_heart/root/rectangle.csv'\n",
    "root_dir = 'C:/Users/Ede/Documents/Iskola/onw_heart/root/DCOMS/'\n",
    "compose1 = Compose([ReScale64(),StandardScale(),ToTensor()])\n",
    "compose2 = Compose([ReScale32(),ToTensor()])\n",
    "ds = RoiDataset(csv_file, root_dir, compose1, compose2)\n",
    "\n",
    "roi = RoiLearn()\n",
    "roi.build_model()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(roi.model.parameters(), lr=0.001)\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(ds,batch_size=8, shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for i_batch, sample_batched in enumerate(dataset_loader):\n",
    "        #print(i_batch, sample_batched['image'].size(),sample_batched['mask'].size())\n",
    "\n",
    "        # Forward Propagation\n",
    "        y_pred = roi.model(sample_batched['image'])\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, sample_batched['mask'])\n",
    "        print('epoch: ', epoch,' loss: ', loss.item())\n",
    "        if 0.1 > loss.item() and not learning_changed:\n",
    "            break\n",
    "                # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataset_loader):\n",
    "            #print(i_batch, sample_batched['image'].size(),sample_batched['mask'].size())\n",
    "\n",
    "            # Forward Propagation\n",
    "    y_pred = roi.model(sample_batched['image'])\n",
    "            \n",
    "    y_pred = np.reshape(y_pred.detach().numpy()[0], (32,32))\n",
    "    img = Image.fromarray(y_pred, 'L')\n",
    "    img.show()\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
