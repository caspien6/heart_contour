{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data were split up to parts. Start multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import clean_raw_data as clean\n",
    "\n",
    "source = 'C:/Users/Ede/Documents/Iskola/onw_hear/root'\n",
    "target = 'C:/Users/Ede/Documents/Iskola/onw_hear/root/cleaned_data'\n",
    "crd = clean.CleanRawData(source, target, 4)\n",
    "crd.create_folder_chunks()\n",
    "print(\"Data were split up to parts. Start multiprocessing.\")\n",
    "lock = clean.Lock()\n",
    "for p in range(crd.thread_num):\n",
    "    fn = crd.clean_data\n",
    "    args = [(lock, crd.new_roots[i], (crd.file_statistic[0][i], crd.file_statistic[1][i])) for i in range(crd.thread_num)]\n",
    "    clean.Process(target=fn, args=(args[p],)).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import png\n",
    "import pydicom\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(n_h, n_out),\n",
    "                     nn.Sigmoid())\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "for epoch in range(50):\n",
    "    # Forward Propagation\n",
    "    y_pred = model(x)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_image('./root/cleaned_data/img_0_22.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4697, 0.4933, 0.4597,  ..., 0.5590, 0.4340, 0.5037]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4690, 0.4919, 0.4609,  ..., 0.5583, 0.4340, 0.5043]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4728, 0.4971, 0.4606,  ..., 0.5576, 0.4346, 0.5071]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4727, 0.4964, 0.4608,  ..., 0.5578, 0.4363, 0.5047]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4745, 0.4926, 0.4629,  ..., 0.5593, 0.4306, 0.5014]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4746, 0.4901, 0.4612,  ..., 0.5581, 0.4285, 0.5016]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4737, 0.4899, 0.4600,  ..., 0.5600, 0.4288, 0.5029]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4735, 0.4925, 0.4597,  ..., 0.5611, 0.4281, 0.5019]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4731, 0.4939, 0.4608,  ..., 0.5618, 0.4273, 0.5030]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4725, 0.4929, 0.4592,  ..., 0.5603, 0.4283, 0.5031]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4721, 0.4944, 0.4584,  ..., 0.5573, 0.4273, 0.5018]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4713, 0.4934, 0.4560,  ..., 0.5588, 0.4274, 0.5000]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4731, 0.4944, 0.4588,  ..., 0.5567, 0.4271, 0.5042]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4722, 0.4947, 0.4599,  ..., 0.5578, 0.4274, 0.5038]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4717, 0.4934, 0.4608,  ..., 0.5590, 0.4288, 0.5050]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4729, 0.4947, 0.4600,  ..., 0.5606, 0.4293, 0.5065]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4743, 0.4951, 0.4607,  ..., 0.5578, 0.4273, 0.5039]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4711, 0.4939, 0.4626,  ..., 0.5546, 0.4291, 0.5037]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4694, 0.4925, 0.4594,  ..., 0.5608, 0.4301, 0.5041]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4708, 0.4938, 0.4635,  ..., 0.5585, 0.4335, 0.5097]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4716, 0.4915, 0.4589,  ..., 0.5591, 0.4336, 0.5047]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4713, 0.4918, 0.4614,  ..., 0.5606, 0.4347, 0.5030]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4712, 0.4934, 0.4618,  ..., 0.5599, 0.4355, 0.5032]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4717, 0.4928, 0.4630,  ..., 0.5603, 0.4333, 0.5057]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4720, 0.4924, 0.4612,  ..., 0.5573, 0.4344, 0.5043]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4736, 0.4898, 0.4833,  ..., 0.5487, 0.4432, 0.4725]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4699, 0.4866, 0.4803,  ..., 0.5477, 0.4454, 0.4677]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4708, 0.4874, 0.4786,  ..., 0.5496, 0.4438, 0.4675]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4719, 0.4871, 0.4842,  ..., 0.5492, 0.4470, 0.4696]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4697, 0.4854, 0.4837,  ..., 0.5497, 0.4454, 0.4696]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4710, 0.4853, 0.4853,  ..., 0.5506, 0.4408, 0.4688]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4729, 0.4832, 0.4855,  ..., 0.5485, 0.4464, 0.4703]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4725, 0.4844, 0.4822,  ..., 0.5504, 0.4480, 0.4678]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4736, 0.4864, 0.4819,  ..., 0.5545, 0.4464, 0.4682]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4717, 0.4873, 0.4817,  ..., 0.5525, 0.4457, 0.4699]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4705, 0.4873, 0.4831,  ..., 0.5531, 0.4414, 0.4712]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4709, 0.4854, 0.4807,  ..., 0.5543, 0.4433, 0.4689]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4712, 0.4862, 0.4828,  ..., 0.5537, 0.4388, 0.4711]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4707, 0.4873, 0.4793,  ..., 0.5571, 0.4371, 0.4675]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4707, 0.4865, 0.4789,  ..., 0.5569, 0.4419, 0.4680]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4701, 0.4883, 0.4816,  ..., 0.5549, 0.4414, 0.4694]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4708, 0.4909, 0.4835,  ..., 0.5515, 0.4429, 0.4704]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4695, 0.4869, 0.4828,  ..., 0.5511, 0.4462, 0.4721]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4692, 0.4855, 0.4804,  ..., 0.5502, 0.4464, 0.4703]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4677, 0.4883, 0.4844,  ..., 0.5463, 0.4442, 0.4693]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4677, 0.4839, 0.4801,  ..., 0.5527, 0.4446, 0.4682]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4685, 0.4853, 0.4835,  ..., 0.5497, 0.4470, 0.4718]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4673, 0.4890, 0.4823,  ..., 0.5499, 0.4408, 0.4677]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4682, 0.4898, 0.4846,  ..., 0.5471, 0.4412, 0.4686]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4677, 0.4872, 0.4860,  ..., 0.5494, 0.4448, 0.4713]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4698, 0.4962, 0.4899,  ..., 0.5360, 0.4611, 0.4649]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4706, 0.4914, 0.4799,  ..., 0.5418, 0.4660, 0.4635]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4744, 0.4911, 0.4825,  ..., 0.5434, 0.4636, 0.4695]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4730, 0.4914, 0.4863,  ..., 0.5424, 0.4622, 0.4646]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4724, 0.4949, 0.4875,  ..., 0.5384, 0.4638, 0.4626]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4727, 0.4954, 0.4824,  ..., 0.5412, 0.4633, 0.4605]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4723, 0.4964, 0.4866,  ..., 0.5404, 0.4555, 0.4615]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4712, 0.4961, 0.4878,  ..., 0.5466, 0.4555, 0.4628]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4720, 0.4977, 0.4899,  ..., 0.5454, 0.4520, 0.4623]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4707, 0.4975, 0.4861,  ..., 0.5483, 0.4539, 0.4618]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4698, 0.4955, 0.4848,  ..., 0.5477, 0.4509, 0.4586]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4718, 0.4952, 0.4869,  ..., 0.5436, 0.4484, 0.4604]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4743, 0.4938, 0.4831,  ..., 0.5476, 0.4523, 0.4618]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4698, 0.4960, 0.4888,  ..., 0.5433, 0.4511, 0.4631]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4732, 0.4960, 0.4845,  ..., 0.5430, 0.4546, 0.4613]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4735, 0.4951, 0.4860,  ..., 0.5400, 0.4560, 0.4658]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4719, 0.4908, 0.4858,  ..., 0.5409, 0.4582, 0.4664]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4731, 0.4939, 0.4884,  ..., 0.5396, 0.4589, 0.4661]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4735, 0.4913, 0.4852,  ..., 0.5422, 0.4602, 0.4638]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4750, 0.4940, 0.4877,  ..., 0.5410, 0.4584, 0.4643]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4735, 0.4940, 0.4855,  ..., 0.5359, 0.4608, 0.4650]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4693, 0.4958, 0.4891,  ..., 0.5378, 0.4584, 0.4655]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4703, 0.4948, 0.4899,  ..., 0.5368, 0.4614, 0.4674]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4695, 0.4928, 0.4878,  ..., 0.5379, 0.4586, 0.4628]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4706, 0.4936, 0.4887,  ..., 0.5365, 0.4619, 0.4660]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4794, 0.5068, 0.4960,  ..., 0.5429, 0.4922, 0.4714]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4794, 0.5081, 0.4968,  ..., 0.5401, 0.4959, 0.4681]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4801, 0.5063, 0.4923,  ..., 0.5422, 0.4987, 0.4681]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4802, 0.5053, 0.4913,  ..., 0.5436, 0.5023, 0.4726]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4764, 0.5095, 0.4935,  ..., 0.5414, 0.4948, 0.4669]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4773, 0.5110, 0.4933,  ..., 0.5450, 0.4869, 0.4682]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4767, 0.5138, 0.4961,  ..., 0.5485, 0.4841, 0.4686]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4798, 0.5106, 0.4907,  ..., 0.5527, 0.4872, 0.4669]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4776, 0.5115, 0.4936,  ..., 0.5515, 0.4773, 0.4668]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4812, 0.5126, 0.4911,  ..., 0.5523, 0.4843, 0.4672]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4804, 0.5130, 0.4936,  ..., 0.5510, 0.4818, 0.4655]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4788, 0.5153, 0.4975,  ..., 0.5493, 0.4780, 0.4619]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4780, 0.5130, 0.4947,  ..., 0.5498, 0.4832, 0.4644]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4785, 0.5110, 0.4915,  ..., 0.5480, 0.4849, 0.4630]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4794, 0.5089, 0.4890,  ..., 0.5448, 0.4921, 0.4657]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4793, 0.5077, 0.4911,  ..., 0.5437, 0.4929, 0.4684]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4820, 0.5073, 0.4966,  ..., 0.5402, 0.4959, 0.4730]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4811, 0.5081, 0.4956,  ..., 0.5432, 0.4955, 0.4714]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4808, 0.5084, 0.4959,  ..., 0.5416, 0.4917, 0.4680]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4801, 0.5080, 0.4949,  ..., 0.5442, 0.4960, 0.4712]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4797, 0.5085, 0.4943,  ..., 0.5413, 0.4926, 0.4642]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4797, 0.5088, 0.4961,  ..., 0.5415, 0.4923, 0.4704]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4783, 0.5065, 0.4951,  ..., 0.5444, 0.4962, 0.4724]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4765, 0.5103, 0.4978,  ..., 0.5426, 0.4938, 0.4705]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4809, 0.5085, 0.4953,  ..., 0.5442, 0.4969, 0.4698]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5052, 0.5144, 0.4842,  ..., 0.5181, 0.4955, 0.5035]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5040, 0.5160, 0.4820,  ..., 0.5188, 0.4980, 0.5005]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5051, 0.5162, 0.4809,  ..., 0.5197, 0.4952, 0.4954]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5045, 0.5166, 0.4804,  ..., 0.5200, 0.4954, 0.4922]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5044, 0.5154, 0.4852,  ..., 0.5174, 0.4946, 0.4952]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5047, 0.5124, 0.4875,  ..., 0.5172, 0.4913, 0.4961]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5018, 0.5159, 0.4862,  ..., 0.5221, 0.4938, 0.4909]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5035, 0.5118, 0.4854,  ..., 0.5262, 0.4902, 0.4854]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5078, 0.5141, 0.4863,  ..., 0.5243, 0.4866, 0.4864]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5088, 0.5177, 0.4879,  ..., 0.5247, 0.4844, 0.4782]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5062, 0.5146, 0.4876,  ..., 0.5252, 0.4861, 0.4839]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5062, 0.5124, 0.4869,  ..., 0.5248, 0.4909, 0.4846]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5051, 0.5165, 0.4815,  ..., 0.5230, 0.4909, 0.4834]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5023, 0.5145, 0.4835,  ..., 0.5239, 0.4925, 0.4906]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5050, 0.5166, 0.4804,  ..., 0.5219, 0.4943, 0.4924]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5068, 0.5138, 0.4820,  ..., 0.5215, 0.4928, 0.5015]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5082, 0.5132, 0.4855,  ..., 0.5202, 0.4938, 0.5013]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5096, 0.5149, 0.4821,  ..., 0.5209, 0.4971, 0.4972]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5098, 0.5116, 0.4880,  ..., 0.5188, 0.4942, 0.4978]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5084, 0.5126, 0.4875,  ..., 0.5182, 0.4928, 0.4953]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5062, 0.5127, 0.4833,  ..., 0.5186, 0.4955, 0.4944]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5083, 0.5137, 0.4821,  ..., 0.5209, 0.4976, 0.4978]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5071, 0.5174, 0.4809,  ..., 0.5228, 0.4976, 0.4969]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5075, 0.5165, 0.4853,  ..., 0.5175, 0.4958, 0.4992]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5073, 0.5150, 0.4850,  ..., 0.5176, 0.4941, 0.4973]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5159, 0.5146, 0.4839,  ..., 0.4970, 0.5071, 0.4879]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5119, 0.5162, 0.4830,  ..., 0.4987, 0.5086, 0.4903]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5141, 0.5191, 0.4796,  ..., 0.4962, 0.5100, 0.4836]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151, 0.5196, 0.4748,  ..., 0.4954, 0.5100, 0.4830]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5124, 0.5168, 0.4755,  ..., 0.4957, 0.5098, 0.4841]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5155, 0.5175, 0.4794,  ..., 0.4930, 0.5048, 0.4822]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5181, 0.5172, 0.4787,  ..., 0.4984, 0.5058, 0.4807]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182, 0.5144, 0.4843,  ..., 0.4980, 0.5001, 0.4813]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5190, 0.5161, 0.4881,  ..., 0.4948, 0.5003, 0.4839]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5200, 0.5155, 0.4889,  ..., 0.4976, 0.4964, 0.4867]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5212, 0.5132, 0.4901,  ..., 0.4970, 0.4950, 0.4874]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5203, 0.5132, 0.4895,  ..., 0.4928, 0.4978, 0.4829]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5170, 0.5135, 0.4888,  ..., 0.4960, 0.4978, 0.4865]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5184, 0.5164, 0.4833,  ..., 0.4972, 0.4981, 0.4890]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5158, 0.5142, 0.4794,  ..., 0.4996, 0.5006, 0.4897]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5156, 0.5113, 0.4801,  ..., 0.4986, 0.5034, 0.4878]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5155, 0.5096, 0.4787,  ..., 0.4967, 0.5060, 0.4921]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5180, 0.5099, 0.4819,  ..., 0.4966, 0.5059, 0.4900]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5179, 0.5134, 0.4799,  ..., 0.4954, 0.5088, 0.4836]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5180, 0.5144, 0.4871,  ..., 0.4960, 0.5006, 0.4884]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5181, 0.5155, 0.4831,  ..., 0.4954, 0.5054, 0.4870]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5185, 0.5161, 0.4790,  ..., 0.4979, 0.5130, 0.4897]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5171, 0.5156, 0.4800,  ..., 0.4999, 0.5125, 0.4911]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5193, 0.5155, 0.4811,  ..., 0.4962, 0.5096, 0.4844]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5170, 0.5162, 0.4847,  ..., 0.4982, 0.5057, 0.4918]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5221, 0.5255, 0.4824,  ..., 0.4928, 0.5135, 0.4953]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5246, 0.5235, 0.4847,  ..., 0.4941, 0.5067, 0.4960]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197, 0.5254, 0.4799,  ..., 0.4999, 0.5074, 0.4922]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5224, 0.5257, 0.4796,  ..., 0.4955, 0.5117, 0.4913]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267, 0.5289, 0.4774,  ..., 0.4913, 0.5110, 0.4876]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247, 0.5273, 0.4801,  ..., 0.4899, 0.5086, 0.4877]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5272, 0.5267, 0.4815,  ..., 0.4894, 0.5054, 0.4926]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5289, 0.5273, 0.4873,  ..., 0.4948, 0.5042, 0.4983]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5277, 0.5256, 0.4874,  ..., 0.4934, 0.5008, 0.4944]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5277, 0.5280, 0.4857,  ..., 0.4956, 0.5017, 0.4967]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5272, 0.5255, 0.4870,  ..., 0.4923, 0.5040, 0.4957]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5252, 0.5262, 0.4848,  ..., 0.4917, 0.5065, 0.4941]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5233, 0.5257, 0.4830,  ..., 0.4971, 0.5056, 0.4969]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5235, 0.5243, 0.4825,  ..., 0.4938, 0.5040, 0.4936]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236, 0.5227, 0.4826,  ..., 0.4973, 0.5036, 0.4971]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5245, 0.5216, 0.4842,  ..., 0.4977, 0.5046, 0.4979]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5259, 0.5224, 0.4859,  ..., 0.4953, 0.5080, 0.4992]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5265, 0.5233, 0.4873,  ..., 0.4952, 0.5102, 0.5003]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5288, 0.5235, 0.4857,  ..., 0.4917, 0.5096, 0.4928]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273, 0.5230, 0.4847,  ..., 0.4948, 0.5088, 0.4971]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5259, 0.5216, 0.4816,  ..., 0.4942, 0.5117, 0.4984]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5271, 0.5231, 0.4832,  ..., 0.4926, 0.5108, 0.5004]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270, 0.5222, 0.4822,  ..., 0.4947, 0.5114, 0.5010]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5257, 0.5211, 0.4848,  ..., 0.4935, 0.5108, 0.4959]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267, 0.5247, 0.4845,  ..., 0.4921, 0.5133, 0.4937]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5456, 0.5308, 0.4729,  ..., 0.4948, 0.5111, 0.4832]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5464, 0.5333, 0.4728,  ..., 0.4945, 0.5108, 0.4839]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5375, 0.5292, 0.4701,  ..., 0.5013, 0.5092, 0.4844]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5365, 0.5326, 0.4722,  ..., 0.4983, 0.5105, 0.4863]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5451, 0.5360, 0.4691,  ..., 0.4956, 0.5120, 0.4865]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5434, 0.5362, 0.4710,  ..., 0.4900, 0.5125, 0.4866]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5480, 0.5385, 0.4727,  ..., 0.4931, 0.5113, 0.4886]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5517, 0.5392, 0.4753,  ..., 0.4923, 0.5111, 0.4890]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5509, 0.5398, 0.4784,  ..., 0.4912, 0.5105, 0.4888]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5494, 0.5372, 0.4749,  ..., 0.4916, 0.5098, 0.4855]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5497, 0.5393, 0.4759,  ..., 0.4899, 0.5117, 0.4829]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5489, 0.5395, 0.4753,  ..., 0.4896, 0.5152, 0.4829]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5484, 0.5395, 0.4742,  ..., 0.4887, 0.5156, 0.4857]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5444, 0.5361, 0.4729,  ..., 0.4901, 0.5129, 0.4875]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5467, 0.5326, 0.4703,  ..., 0.4963, 0.5121, 0.4830]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5400, 0.5311, 0.4728,  ..., 0.4963, 0.5116, 0.4893]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5410, 0.5307, 0.4713,  ..., 0.4967, 0.5123, 0.4853]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5434, 0.5310, 0.4709,  ..., 0.4937, 0.5118, 0.4883]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5447, 0.5303, 0.4713,  ..., 0.4963, 0.5103, 0.4903]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5459, 0.5329, 0.4757,  ..., 0.4939, 0.5106, 0.4877]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5458, 0.5297, 0.4723,  ..., 0.4938, 0.5092, 0.4852]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5476, 0.5320, 0.4739,  ..., 0.4923, 0.5100, 0.4823]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5437, 0.5329, 0.4753,  ..., 0.4932, 0.5125, 0.4861]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5442, 0.5323, 0.4766,  ..., 0.4909, 0.5119, 0.4871]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5430, 0.5306, 0.4758,  ..., 0.4960, 0.5100, 0.4895]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5672, 0.5375, 0.4960,  ..., 0.5003, 0.5155, 0.4625]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5610, 0.5379, 0.4963,  ..., 0.5000, 0.5187, 0.4611]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5589, 0.5397, 0.4968,  ..., 0.5026, 0.5185, 0.4656]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5606, 0.5427, 0.4967,  ..., 0.4999, 0.5215, 0.4630]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5654, 0.5472, 0.4971,  ..., 0.4982, 0.5200, 0.4612]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5648, 0.5451, 0.4941,  ..., 0.4971, 0.5215, 0.4608]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5658, 0.5461, 0.4968,  ..., 0.4977, 0.5194, 0.4644]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5674, 0.5465, 0.4996,  ..., 0.4954, 0.5168, 0.4664]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5690, 0.5447, 0.5017,  ..., 0.4944, 0.5128, 0.4691]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5699, 0.5456, 0.5033,  ..., 0.4936, 0.5117, 0.4682]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5717, 0.5444, 0.5015,  ..., 0.4933, 0.5105, 0.4662]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5700, 0.5445, 0.5005,  ..., 0.4942, 0.5153, 0.4683]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5680, 0.5433, 0.4977,  ..., 0.4977, 0.5155, 0.4657]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5662, 0.5460, 0.4989,  ..., 0.4997, 0.5167, 0.4664]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5636, 0.5436, 0.4961,  ..., 0.5008, 0.5148, 0.4680]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5626, 0.5392, 0.4931,  ..., 0.5033, 0.5132, 0.4697]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5608, 0.5382, 0.4898,  ..., 0.5020, 0.5174, 0.4620]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5643, 0.5383, 0.4921,  ..., 0.5005, 0.5155, 0.4609]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5640, 0.5398, 0.4943,  ..., 0.5007, 0.5131, 0.4632]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5636, 0.5366, 0.4945,  ..., 0.5016, 0.5150, 0.4634]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5636, 0.5368, 0.4946,  ..., 0.4991, 0.5184, 0.4649]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5636, 0.5369, 0.4920,  ..., 0.5026, 0.5161, 0.4610]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5651, 0.5367, 0.4927,  ..., 0.5016, 0.5143, 0.4567]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5651, 0.5365, 0.4974,  ..., 0.5021, 0.5164, 0.4596]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5647, 0.5357, 0.4941,  ..., 0.5003, 0.5184, 0.4578]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5677, 0.5402, 0.4945,  ..., 0.5023, 0.5239, 0.4752]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5636, 0.5418, 0.4962,  ..., 0.5051, 0.5234, 0.4766]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5671, 0.5460, 0.4964,  ..., 0.5031, 0.5266, 0.4780]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5650, 0.5484, 0.4967,  ..., 0.4996, 0.5296, 0.4718]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5667, 0.5492, 0.4978,  ..., 0.4961, 0.5268, 0.4700]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5618, 0.5529, 0.5012,  ..., 0.4981, 0.5252, 0.4742]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5617, 0.5526, 0.5022,  ..., 0.4958, 0.5221, 0.4774]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5623, 0.5553, 0.5045,  ..., 0.4966, 0.5217, 0.4777]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5657, 0.5592, 0.5058,  ..., 0.4964, 0.5171, 0.4777]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5666, 0.5600, 0.5060,  ..., 0.4986, 0.5150, 0.4787]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5634, 0.5606, 0.5055,  ..., 0.4977, 0.5169, 0.4773]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5619, 0.5582, 0.5015,  ..., 0.5007, 0.5173, 0.4745]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5610, 0.5579, 0.5016,  ..., 0.4963, 0.5186, 0.4756]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5612, 0.5542, 0.4986,  ..., 0.4993, 0.5179, 0.4721]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5648, 0.5502, 0.4953,  ..., 0.4997, 0.5170, 0.4711]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5655, 0.5495, 0.4940,  ..., 0.4968, 0.5203, 0.4689]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5670, 0.5497, 0.4932,  ..., 0.5003, 0.5209, 0.4651]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5644, 0.5475, 0.4935,  ..., 0.5025, 0.5240, 0.4650]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5656, 0.5455, 0.4917,  ..., 0.5026, 0.5230, 0.4651]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5641, 0.5432, 0.4948,  ..., 0.5043, 0.5225, 0.4711]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5655, 0.5420, 0.4935,  ..., 0.5039, 0.5231, 0.4700]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5632, 0.5419, 0.4938,  ..., 0.5046, 0.5219, 0.4729]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5700, 0.5410, 0.4944,  ..., 0.5022, 0.5211, 0.4709]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5674, 0.5402, 0.4962,  ..., 0.5006, 0.5224, 0.4701]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5679, 0.5364, 0.4953,  ..., 0.5008, 0.5197, 0.4709]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5668, 0.5209, 0.5044,  ..., 0.4961, 0.5170, 0.4806]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5696, 0.5268, 0.5018,  ..., 0.4968, 0.5203, 0.4812]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5674, 0.5279, 0.5017,  ..., 0.4957, 0.5223, 0.4820]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5602, 0.5311, 0.5074,  ..., 0.4967, 0.5196, 0.4813]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5529, 0.5326, 0.5079,  ..., 0.4966, 0.5124, 0.4850]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5469, 0.5346, 0.5107,  ..., 0.4946, 0.5107, 0.4864]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5471, 0.5360, 0.5119,  ..., 0.4918, 0.5069, 0.4842]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5483, 0.5335, 0.5094,  ..., 0.4907, 0.5053, 0.4844]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5544, 0.5314, 0.5107,  ..., 0.4881, 0.5074, 0.4861]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5549, 0.5321, 0.5119,  ..., 0.4875, 0.5058, 0.4880]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5560, 0.5330, 0.5076,  ..., 0.4869, 0.5069, 0.4826]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5580, 0.5336, 0.5083,  ..., 0.4872, 0.5088, 0.4801]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5586, 0.5317, 0.5057,  ..., 0.4903, 0.5083, 0.4815]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5580, 0.5333, 0.5036,  ..., 0.4949, 0.5087, 0.4814]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5593, 0.5379, 0.5053,  ..., 0.4960, 0.5078, 0.4828]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5589, 0.5355, 0.5065,  ..., 0.4943, 0.5093, 0.4828]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5610, 0.5322, 0.5063,  ..., 0.4928, 0.5111, 0.4804]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5621, 0.5304, 0.5054,  ..., 0.4913, 0.5125, 0.4798]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5659, 0.5290, 0.4999,  ..., 0.4954, 0.5173, 0.4781]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5686, 0.5280, 0.4991,  ..., 0.4936, 0.5180, 0.4768]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5660, 0.5253, 0.5001,  ..., 0.4956, 0.5166, 0.4769]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5646, 0.5265, 0.5016,  ..., 0.4937, 0.5173, 0.4755]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5653, 0.5243, 0.5047,  ..., 0.4964, 0.5161, 0.4754]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5655, 0.5214, 0.5050,  ..., 0.4979, 0.5184, 0.4770]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5651, 0.5204, 0.5060,  ..., 0.4980, 0.5192, 0.4803]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5601, 0.5161, 0.5180,  ..., 0.4820, 0.4999, 0.4822]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5576, 0.5197, 0.5177,  ..., 0.4880, 0.5037, 0.4865]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5569, 0.5254, 0.5138,  ..., 0.4877, 0.5104, 0.4971]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5522, 0.5239, 0.5161,  ..., 0.4856, 0.5074, 0.4962]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5521, 0.5189, 0.5132,  ..., 0.4818, 0.5038, 0.4872]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5529, 0.5188, 0.5172,  ..., 0.4794, 0.5034, 0.4870]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5546, 0.5180, 0.5164,  ..., 0.4773, 0.5038, 0.4857]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5533, 0.5175, 0.5172,  ..., 0.4782, 0.5017, 0.4825]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5523, 0.5178, 0.5175,  ..., 0.4764, 0.4959, 0.4837]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5535, 0.5168, 0.5180,  ..., 0.4725, 0.4970, 0.4843]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5527, 0.5164, 0.5184,  ..., 0.4730, 0.4979, 0.4800]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5524, 0.5177, 0.5197,  ..., 0.4736, 0.4981, 0.4774]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5558, 0.5182, 0.5177,  ..., 0.4765, 0.5016, 0.4791]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5630, 0.5200, 0.5142,  ..., 0.4754, 0.5011, 0.4844]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5629, 0.5220, 0.5152,  ..., 0.4769, 0.5020, 0.4840]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5602, 0.5200, 0.5156,  ..., 0.4788, 0.5004, 0.4864]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5581, 0.5233, 0.5168,  ..., 0.4806, 0.4983, 0.4869]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5551, 0.5253, 0.5181,  ..., 0.4789, 0.4961, 0.4847]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5576, 0.5235, 0.5140,  ..., 0.4849, 0.4971, 0.4853]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5607, 0.5213, 0.5117,  ..., 0.4847, 0.5002, 0.4832]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5612, 0.5202, 0.5156,  ..., 0.4827, 0.4975, 0.4829]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5573, 0.5195, 0.5161,  ..., 0.4828, 0.5006, 0.4838]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5616, 0.5190, 0.5148,  ..., 0.4810, 0.5002, 0.4835]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5610, 0.5163, 0.5167,  ..., 0.4821, 0.5000, 0.4836]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5593, 0.5170, 0.5169,  ..., 0.4819, 0.5000, 0.4829]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5654, 0.5215, 0.5212,  ..., 0.4779, 0.4941, 0.4737]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5660, 0.5211, 0.5184,  ..., 0.4769, 0.4996, 0.4763]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5663, 0.5203, 0.5214,  ..., 0.4754, 0.5026, 0.4739]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5690, 0.5204, 0.5181,  ..., 0.4757, 0.4965, 0.4714]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5662, 0.5154, 0.5182,  ..., 0.4777, 0.4940, 0.4680]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5660, 0.5141, 0.5171,  ..., 0.4758, 0.4929, 0.4717]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5645, 0.5120, 0.5180,  ..., 0.4763, 0.4907, 0.4716]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5654, 0.5135, 0.5185,  ..., 0.4742, 0.4896, 0.4685]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5646, 0.5131, 0.5169,  ..., 0.4761, 0.4919, 0.4713]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5667, 0.5139, 0.5175,  ..., 0.4746, 0.4916, 0.4681]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5687, 0.5142, 0.5171,  ..., 0.4734, 0.4913, 0.4691]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5679, 0.5136, 0.5173,  ..., 0.4752, 0.4907, 0.4695]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5673, 0.5149, 0.5168,  ..., 0.4747, 0.4894, 0.4676]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5675, 0.5169, 0.5167,  ..., 0.4757, 0.4902, 0.4658]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5654, 0.5198, 0.5177,  ..., 0.4737, 0.4899, 0.4662]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5649, 0.5206, 0.5179,  ..., 0.4733, 0.4877, 0.4666]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5654, 0.5196, 0.5203,  ..., 0.4749, 0.4863, 0.4689]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5633, 0.5198, 0.5182,  ..., 0.4768, 0.4878, 0.4687]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5612, 0.5212, 0.5159,  ..., 0.4745, 0.4879, 0.4729]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5649, 0.5204, 0.5176,  ..., 0.4724, 0.4928, 0.4752]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5614, 0.5200, 0.5191,  ..., 0.4742, 0.4943, 0.4809]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5616, 0.5228, 0.5247,  ..., 0.4751, 0.4941, 0.4816]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5601, 0.5250, 0.5258,  ..., 0.4767, 0.4932, 0.4830]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5601, 0.5225, 0.5224,  ..., 0.4754, 0.4942, 0.4787]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5661, 0.5241, 0.5214,  ..., 0.4764, 0.4969, 0.4777]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5618, 0.5004, 0.5253,  ..., 0.4858, 0.4898, 0.4790]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5630, 0.5000, 0.5215,  ..., 0.4850, 0.4969, 0.4818]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5634, 0.4992, 0.5197,  ..., 0.4831, 0.4946, 0.4825]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5600, 0.5023, 0.5125,  ..., 0.4828, 0.4926, 0.4772]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5591, 0.5020, 0.5104,  ..., 0.4870, 0.4913, 0.4811]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5577, 0.5021, 0.5088,  ..., 0.4878, 0.4880, 0.4855]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5557, 0.5002, 0.5086,  ..., 0.4888, 0.4834, 0.4859]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5548, 0.5004, 0.5066,  ..., 0.4858, 0.4860, 0.4843]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5553, 0.4997, 0.5084,  ..., 0.4868, 0.4862, 0.4879]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5563, 0.4989, 0.5094,  ..., 0.4865, 0.4853, 0.4867]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5574, 0.4981, 0.5093,  ..., 0.4836, 0.4874, 0.4821]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5637, 0.4981, 0.5104,  ..., 0.4823, 0.4888, 0.4822]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5604, 0.4946, 0.5139,  ..., 0.4831, 0.4871, 0.4795]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5615, 0.4963, 0.5107,  ..., 0.4832, 0.4843, 0.4795]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5584, 0.4984, 0.5133,  ..., 0.4819, 0.4881, 0.4792]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5600, 0.5033, 0.5137,  ..., 0.4831, 0.4883, 0.4808]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5596, 0.5038, 0.5152,  ..., 0.4832, 0.4905, 0.4776]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5583, 0.5047, 0.5175,  ..., 0.4844, 0.4885, 0.4826]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5603, 0.5036, 0.5190,  ..., 0.4808, 0.4907, 0.4848]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5602, 0.5042, 0.5185,  ..., 0.4806, 0.4914, 0.4841]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5582, 0.5036, 0.5198,  ..., 0.4822, 0.4928, 0.4790]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5577, 0.5015, 0.5258,  ..., 0.4823, 0.4934, 0.4793]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5613, 0.5043, 0.5269,  ..., 0.4811, 0.4917, 0.4822]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5608, 0.5043, 0.5259,  ..., 0.4831, 0.4935, 0.4850]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5616, 0.5025, 0.5270,  ..., 0.4875, 0.4885, 0.4803]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241, 0.4896, 0.5163,  ..., 0.5017, 0.4854, 0.5221]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5237, 0.4899, 0.5118,  ..., 0.5024, 0.4874, 0.5230]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5224, 0.4889, 0.5126,  ..., 0.5029, 0.4887, 0.5253]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5199, 0.4907, 0.5115,  ..., 0.5031, 0.4852, 0.5266]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5203, 0.4922, 0.5164,  ..., 0.4979, 0.4903, 0.5332]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5200, 0.4893, 0.5185,  ..., 0.5034, 0.4905, 0.5372]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5221, 0.4943, 0.5192,  ..., 0.5014, 0.4915, 0.5375]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5230, 0.4942, 0.5215,  ..., 0.5007, 0.4882, 0.5393]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5212, 0.4958, 0.5234,  ..., 0.5046, 0.4880, 0.5408]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5233, 0.4966, 0.5223,  ..., 0.5051, 0.4925, 0.5404]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209, 0.4970, 0.5230,  ..., 0.5041, 0.4909, 0.5366]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5183, 0.4943, 0.5252,  ..., 0.5066, 0.4871, 0.5346]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207, 0.4916, 0.5251,  ..., 0.5088, 0.4843, 0.5317]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5199, 0.4926, 0.5246,  ..., 0.5063, 0.4853, 0.5306]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5244, 0.4934, 0.5199,  ..., 0.5044, 0.4887, 0.5344]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5234, 0.4920, 0.5201,  ..., 0.5026, 0.4892, 0.5295]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226, 0.4928, 0.5190,  ..., 0.5014, 0.4869, 0.5305]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5224, 0.4919, 0.5177,  ..., 0.5004, 0.4842, 0.5308]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210, 0.4905, 0.5167,  ..., 0.4957, 0.4892, 0.5305]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5198, 0.4922, 0.5166,  ..., 0.4956, 0.4937, 0.5290]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5211, 0.4919, 0.5170,  ..., 0.4971, 0.4980, 0.5303]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219, 0.4915, 0.5183,  ..., 0.4990, 0.4975, 0.5302]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210, 0.4903, 0.5175,  ..., 0.5011, 0.4956, 0.5320]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219, 0.4926, 0.5174,  ..., 0.5029, 0.4912, 0.5293]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5246, 0.4921, 0.5188,  ..., 0.4992, 0.4862, 0.5217]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "roi = RoiLearn()\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "preprocessor.create_datasetLoader('./root')\n",
    "#preprocessor.show_some_loadedData()\n",
    "\n",
    "roi.build_model()\n",
    "dataLoader = preprocessor.get_dataLoader()\n",
    "\n",
    "roi.propagate_from_dataLoader(dataLoader)\n",
    "#y_pred = roi.propagate().detach().numpy()\n",
    "#save_image(y_pred[0,0,:,:]*255, 'pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class RoiLearn:\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(44)\n",
    "        self.conv1 = nn.Conv2d(1,100, (11,11))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d(6)\n",
    "        self.flatten = Flatten()\n",
    "        self.full = nn.Linear(8100,1024)\n",
    "            \n",
    "    def build_model(self):\n",
    "        self.model = nn.Sequential(self.conv1,\n",
    "                            self.avgpool,\n",
    "                            self.relu,\n",
    "                            self.flatten,\n",
    "                            self.full,\n",
    "                            self.sigmoid\n",
    "                            )\n",
    "        self.model = self.model.double()\n",
    "    \n",
    "    def propagate_from_dataLoader(self,dl):\n",
    "        for i_batch, sample_batched in enumerate(dl):\n",
    "            print(self.model(sample_batched[0]))\n",
    "    \n",
    "    def load_and_prepare_image(self, path):\n",
    "        p = load_image(path)\n",
    "        normed_matrix = normalize(p)\n",
    "        normed_matrix = np.expand_dims(normed_matrix, 0)\n",
    "        normed_matrix = np.expand_dims(normed_matrix, 0)\n",
    "        self.x = normed_matrix\n",
    "        self.x = torch.from_numpy(self.x)\n",
    "    \n",
    "    def load_images(self, folder_name):\n",
    "        images = []\n",
    "        dcm_files = os.listdir(folder_name)\n",
    "        for file in dcm_files:\n",
    "\n",
    "            if file.find('.png') != -1:\n",
    "                temp_img = load_image(folder_name + file)\n",
    "                images.append(temp_img)\n",
    "                \n",
    "        return images\n",
    "    \n",
    "    def propagate(self):\n",
    "        return self.model(self.x)\n",
    "    \n",
    "    def save_image( npdata, outfilename ) :\n",
    "        img = Image.fromarray( np.asarray( np.clip(npdata,0,255), dtype=\"uint8\"), \"L\" )\n",
    "        img.save( outfilename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pydicom as dicom\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torchvision.datasets as ds\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def preprocess_data(self,img):\n",
    "        img = img.resize((64,64),Image.ANTIALIAS)\n",
    "        img = img.convert('LA')\n",
    "        data = np.asarray( img, dtype=\"float\" )[:,:,:1]\n",
    "        data = np.swapaxes(data, 0, 2)\n",
    "        data = self.scaler.fit_transform(data)\n",
    "        return data\n",
    "    \n",
    "    def preprocess_dcm(self,img):\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((64,64),Image.ANTIALIAS)\n",
    "        img = img.convert('LA')\n",
    "        data = np.asarray( img, dtype=\"float\" )[:,:,:1]\n",
    "        #channel - height swap\n",
    "        data = np.swapaxes(data, 0, 2)\n",
    "        data = np.swapaxes(data, 1, 2)\n",
    "        data[0] = self.scaler.fit_transform(data[0])\n",
    "        return data\n",
    "    \n",
    "    def load_image(self, infilename ):\n",
    "        img = Image.open( infilename )\n",
    "        img.load()\n",
    "        return img\n",
    "    \n",
    "    def load_dcm(self,infilename):\n",
    "        temp_ds = dicom.dcmread(infilename).pixel_array\n",
    "        return temp_ds\n",
    "\n",
    "    def save_image( self,npdata, outfilename ):\n",
    "        img = Image.fromarray( np.asarray( np.clip(npdata,0,255), dtype=\"uint8\"), \"L\" )\n",
    "        img.save( outfilename )\n",
    "        \n",
    "    def create_datasetLoader(self, folder):\n",
    "        dataset = ds.DatasetFolder(folder, self.load_dcm, ['.dcm'], self.preprocess_dcm)\n",
    "        self.data = torch.utils.data.DataLoader(dataset)\n",
    "        return self.data\n",
    "    \n",
    "    def get_dataLoader(self):\n",
    "        return self.data\n",
    "    \n",
    "    def show_some_loadedData(self):\n",
    "        if (self.data == None):\n",
    "            return\n",
    "        for i_batch, sample_batched in enumerate(self.data):\n",
    "            print(i_batch, sample_batched[0].size(),sample_batched[1].size())\n",
    "            print(sample_batched[0])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
