{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(n_h, n_out),\n",
    "                     nn.Sigmoid())\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "for epoch in range(50):\n",
    "    # Forward Propagation\n",
    "    y_pred = model(x)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_image('./root/cleaned_data/img_0_22.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import png\n",
    "import pydicom\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from roi import RoiLearn\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roii = RoiLearn()\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "dataLoader = preprocessor.create_datasetLoaderDCM('./root')\n",
    "preprocessor.show_some_loadedData()\n",
    "\n",
    "roii.build_model()\n",
    "\n",
    "roii.propagate_from_dataLoader(dataLoader)\n",
    "#y_pred = roi.propagate().detach().numpy()\n",
    "#save_image(y_pred[0,0,:,:]*255, 'pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from dicom_reader import DCMreader\n",
    "\n",
    "class RoiDataset(Dataset):\n",
    "    \"\"\"Roi dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with contour data.\n",
    "            root_dir (string): Directory for .dcm images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        'height is  (y length) width is  (x length)'\n",
    "        self.contour_data = pd.read_csv(csv_file,sep=';', names=('slice', 'frame', 'xmin', 'ymin', 'height','width' ))\n",
    "        self.dcm_images = DCMreader(root_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.contour_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cont = ds.contour_data.iloc[idx]\n",
    "        sl = int(cont['slice'])\n",
    "        fr = int(cont['frame'])\n",
    "        \n",
    "        mask = np.zeros((224,224))\n",
    "        mask[ int(cont['ymin']): int(cont['ymin']) + int(cont['height']),int(cont['xmin']): int(cont['xmin']) + int(cont['width'])] = 1\n",
    "        image = self.dcm_images.get_image(sl,fr)\n",
    "        \n",
    "        sample = {'image': image, 'mask': mask}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "        if self.target_transform:\n",
    "            sample['mask'] = self.target_transform(sample['mask'])\n",
    "\n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "class ReScale64(object):\n",
    "    \"\"\"Scale down ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data = resize(data, (64, 64))\n",
    "        return data\n",
    "\n",
    "\n",
    "class ReScale32(object):\n",
    "    \"\"\"Scale down ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data = resize(data, (32, 32))\n",
    "        data = np.reshape(data, (1024))\n",
    "        return data\n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return torch.from_numpy(data)\n",
    "    \n",
    "class StandardScale(object):\n",
    "    \"\"\"Standard scale ndarrays.\"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        scaler = StandardScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "        \n",
    "        # add color axis because\n",
    "        # numpy image: H x W\n",
    "        # torch image: C X H X W\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torchvision.transforms import Compose\n",
    "from roi_dataset import RoiDataset\n",
    "import transform_classes\n",
    "from roi import RoiLearn\n",
    "import torch\n",
    "\n",
    "\n",
    "csv_file = 'C:/Users/Ede/Documents/Iskola/onw_heart/root/rectangle.csv'\n",
    "root_dir = 'C:/Users/Ede/Documents/Iskola/onw_heart/root/DCOMS/'\n",
    "compose1 = Compose([transform_classes.ReScale64(),transform_classes.StandardScale(),transform_classes.ToTensor()])\n",
    "compose2 = Compose([transform_classes.ReScale32(),transform_classes.ToTensor()])\n",
    "ds = RoiDataset(csv_file, root_dir, compose1, compose2)\n",
    "\n",
    "roi = RoiLearn()\n",
    "roi.build_model()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(roi.model.parameters(), lr=0.001)\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(ds,batch_size=8, shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.08253097283586536\n",
      "epoch:  0  loss:  0.026261991902712487\n",
      "epoch:  0  loss:  0.016110081718059506\n",
      "epoch:  1  loss:  0.012049676664739665\n",
      "epoch:  1  loss:  0.011122760356945293\n",
      "epoch:  1  loss:  0.008210549204470601\n",
      "epoch:  2  loss:  0.007229371201847472\n",
      "epoch:  2  loss:  0.012158255233043667\n",
      "epoch:  2  loss:  0.005626429154125917\n",
      "epoch:  3  loss:  0.008269149023594062\n",
      "epoch:  3  loss:  0.005766683162003667\n",
      "epoch:  3  loss:  0.007672260337395062\n",
      "epoch:  4  loss:  0.008784636414877478\n",
      "epoch:  4  loss:  0.004289344876109282\n",
      "epoch:  4  loss:  0.007149378953071775\n",
      "epoch:  5  loss:  0.0046511020756120555\n",
      "epoch:  5  loss:  0.008546228045754953\n",
      "epoch:  5  loss:  0.004009159913408088\n",
      "epoch:  6  loss:  0.005076484779999988\n",
      "epoch:  6  loss:  0.005562846333357329\n",
      "epoch:  6  loss:  0.003992280149061337\n",
      "epoch:  7  loss:  0.005525553360605247\n",
      "epoch:  7  loss:  0.002200583746719563\n",
      "epoch:  7  loss:  0.004353256973290976\n",
      "epoch:  8  loss:  0.0030114904320407147\n",
      "epoch:  8  loss:  0.0014189196871940604\n",
      "epoch:  8  loss:  0.006797763576668085\n",
      "epoch:  9  loss:  0.003706354862772521\n",
      "epoch:  9  loss:  0.0027525059131761863\n",
      "epoch:  9  loss:  0.002268628425517053\n",
      "epoch:  10  loss:  0.002194721666318264\n",
      "epoch:  10  loss:  0.0017379861034823752\n",
      "epoch:  10  loss:  0.004958110564324018\n",
      "epoch:  11  loss:  0.002974644054056146\n",
      "epoch:  11  loss:  0.0017826566108965793\n",
      "epoch:  11  loss:  0.0018262392178520718\n",
      "epoch:  12  loss:  0.0016225508609245805\n",
      "epoch:  12  loss:  0.0017088393673426326\n",
      "epoch:  12  loss:  0.002803717803347506\n",
      "epoch:  13  loss:  0.0012680707617867303\n",
      "epoch:  13  loss:  0.002385763353523657\n",
      "epoch:  13  loss:  0.001353379111385303\n",
      "epoch:  14  loss:  0.0008383636191911724\n",
      "epoch:  14  loss:  0.0014149236677957954\n",
      "epoch:  14  loss:  0.002654858779651785\n",
      "epoch:  15  loss:  0.0012300799783072779\n",
      "epoch:  15  loss:  0.0013560034690076194\n",
      "epoch:  15  loss:  0.0012328207697317353\n",
      "epoch:  16  loss:  0.0009131120392887347\n",
      "epoch:  16  loss:  0.0018488243427834934\n",
      "epoch:  16  loss:  0.0006062907078594203\n",
      "epoch:  17  loss:  0.0005105340586411701\n",
      "epoch:  17  loss:  0.0021648302646494616\n",
      "epoch:  17  loss:  0.0005984205134057822\n",
      "epoch:  18  loss:  0.0013524625896258592\n",
      "epoch:  18  loss:  0.0008163068220344549\n",
      "epoch:  18  loss:  0.0006038245785801465\n",
      "epoch:  19  loss:  0.0015168617244522213\n",
      "epoch:  19  loss:  0.0006046353562277746\n",
      "epoch:  19  loss:  0.0004391831945267928\n",
      "epoch:  20  loss:  0.0006487403477335723\n",
      "epoch:  20  loss:  0.000920037964168089\n",
      "epoch:  20  loss:  0.0011129606956175244\n",
      "epoch:  21  loss:  0.0004620012985791913\n",
      "epoch:  21  loss:  0.0009727127524604801\n",
      "epoch:  21  loss:  0.0008555376839361351\n",
      "epoch:  22  loss:  0.0006644860892762425\n",
      "epoch:  22  loss:  0.0008085869634489758\n",
      "epoch:  22  loss:  0.0007731255191394238\n",
      "epoch:  23  loss:  0.0009007834321982121\n",
      "epoch:  23  loss:  0.000761696124941143\n",
      "epoch:  23  loss:  0.0002324179100618797\n",
      "epoch:  24  loss:  0.000671362369506076\n",
      "epoch:  24  loss:  0.0007662808580200048\n",
      "epoch:  24  loss:  0.00042738381146501577\n",
      "epoch:  25  loss:  0.000714347249111444\n",
      "epoch:  25  loss:  0.00075413428405172\n",
      "epoch:  25  loss:  0.00024823611705589307\n",
      "epoch:  26  loss:  0.00014325450643088545\n",
      "epoch:  26  loss:  0.001207212968426624\n",
      "epoch:  26  loss:  0.00031092434173975094\n",
      "epoch:  27  loss:  0.00115061938247109\n",
      "epoch:  27  loss:  0.00026907269984297\n",
      "epoch:  27  loss:  7.519639865497138e-05\n",
      "epoch:  28  loss:  0.00020022964015956103\n",
      "epoch:  28  loss:  0.0011061106428582681\n",
      "epoch:  28  loss:  0.00010650991031191862\n",
      "epoch:  29  loss:  0.00016428227702436083\n",
      "epoch:  29  loss:  0.0006035560346526342\n",
      "epoch:  29  loss:  0.0008732467859746453\n",
      "epoch:  30  loss:  0.0009488879270290427\n",
      "epoch:  30  loss:  0.00014868485969127233\n",
      "epoch:  30  loss:  0.00019976699972679016\n",
      "epoch:  31  loss:  0.00015912283936268608\n",
      "epoch:  31  loss:  0.00011596704223098787\n",
      "epoch:  31  loss:  0.0016713401975034792\n",
      "epoch:  32  loss:  0.0005933085750893522\n",
      "epoch:  32  loss:  0.0005971650838792206\n",
      "epoch:  32  loss:  0.00010836772294603314\n",
      "epoch:  33  loss:  7.416137597234596e-05\n",
      "epoch:  33  loss:  0.0010376908048406058\n",
      "epoch:  33  loss:  0.0001368824740678269\n",
      "epoch:  34  loss:  0.00012379909518268813\n",
      "epoch:  34  loss:  0.0004898901461616215\n",
      "epoch:  34  loss:  0.0008039156455439537\n",
      "epoch:  35  loss:  0.00012866596893632462\n",
      "epoch:  35  loss:  0.0005318455953811801\n",
      "epoch:  35  loss:  0.0007082671831495585\n",
      "epoch:  36  loss:  0.00012897943689034805\n",
      "epoch:  36  loss:  0.00011954737375462865\n",
      "epoch:  36  loss:  0.001374680499360785\n",
      "epoch:  37  loss:  7.056337634021864e-05\n",
      "epoch:  37  loss:  0.0008509056838330041\n",
      "epoch:  37  loss:  0.00012044874005350125\n",
      "epoch:  38  loss:  0.0001483986859989459\n",
      "epoch:  38  loss:  0.00046064412880949304\n",
      "epoch:  38  loss:  0.0005296059076877228\n",
      "epoch:  39  loss:  0.0003579039638536158\n",
      "epoch:  39  loss:  0.00012288892137373215\n",
      "epoch:  39  loss:  0.00070421550691643\n",
      "epoch:  40  loss:  0.0005018227979425253\n",
      "epoch:  40  loss:  8.900957111142191e-05\n",
      "epoch:  40  loss:  0.0005135077639248687\n",
      "epoch:  41  loss:  9.81762606968075e-05\n",
      "epoch:  41  loss:  0.0007191013231422184\n",
      "epoch:  41  loss:  9.322085694926127e-05\n",
      "epoch:  42  loss:  0.00044663895732117867\n",
      "epoch:  42  loss:  0.0003773714120046959\n",
      "epoch:  42  loss:  6.37625060452703e-05\n",
      "epoch:  43  loss:  0.0003537466054754274\n",
      "epoch:  43  loss:  7.73618996161039e-05\n",
      "epoch:  43  loss:  0.0006544470252438525\n",
      "epoch:  44  loss:  8.495154638570862e-05\n",
      "epoch:  44  loss:  0.0004463214353555054\n",
      "epoch:  44  loss:  0.00046297650846103985\n",
      "epoch:  45  loss:  0.0003518433378744365\n",
      "epoch:  45  loss:  5.390978613072868e-05\n",
      "epoch:  45  loss:  0.0006483717263004956\n",
      "epoch:  46  loss:  0.0004623898596091453\n",
      "epoch:  46  loss:  0.0002944926749484226\n",
      "epoch:  46  loss:  7.982338008326518e-05\n",
      "epoch:  47  loss:  8.411306518923045e-05\n",
      "epoch:  47  loss:  0.0006728533432445152\n",
      "epoch:  47  loss:  6.69780756795339e-05\n",
      "epoch:  48  loss:  0.000680141231914078\n",
      "epoch:  48  loss:  6.170678400509744e-05\n",
      "epoch:  48  loss:  7.019194905595666e-05\n",
      "epoch:  49  loss:  3.829792737272884e-05\n",
      "epoch:  49  loss:  0.0003058847644744778\n",
      "epoch:  49  loss:  0.0006935253233017076\n",
      "epoch:  50  loss:  6.712911703709485e-05\n",
      "epoch:  50  loss:  0.0006689874217980128\n",
      "epoch:  50  loss:  5.6576198699748104e-05\n",
      "epoch:  51  loss:  4.062835747406773e-05\n",
      "epoch:  51  loss:  0.0004169192536904692\n",
      "epoch:  51  loss:  0.0004879447141149898\n",
      "epoch:  52  loss:  0.0004261257189498374\n",
      "epoch:  52  loss:  6.553062082655458e-05\n",
      "epoch:  52  loss:  0.0004248585393632022\n",
      "epoch:  53  loss:  0.0006871506667400408\n",
      "epoch:  53  loss:  4.325467505020771e-05\n",
      "epoch:  53  loss:  3.867981113270977e-05\n",
      "epoch:  54  loss:  6.112560527575707e-05\n",
      "epoch:  54  loss:  0.00041994989216425515\n",
      "epoch:  54  loss:  0.00042803913529775907\n",
      "epoch:  55  loss:  0.0006634622864752195\n",
      "epoch:  55  loss:  4.839679071479967e-05\n",
      "epoch:  55  loss:  4.772122442323854e-05\n",
      "epoch:  56  loss:  0.00041646655413877756\n",
      "epoch:  56  loss:  4.228371508460395e-05\n",
      "epoch:  56  loss:  0.0004481162158858432\n",
      "epoch:  57  loss:  5.0255230498705835e-05\n",
      "epoch:  57  loss:  4.6880257342398806e-05\n",
      "epoch:  57  loss:  0.0010206246686015217\n",
      "epoch:  58  loss:  0.00027115525041656734\n",
      "epoch:  58  loss:  5.281385932256444e-05\n",
      "epoch:  58  loss:  0.0006487386455682456\n",
      "epoch:  59  loss:  0.0004174191814117258\n",
      "epoch:  59  loss:  3.532888464922818e-05\n",
      "epoch:  59  loss:  0.000439051669371077\n",
      "epoch:  60  loss:  5.2455958667911384e-05\n",
      "epoch:  60  loss:  0.0002839154429886931\n",
      "epoch:  60  loss:  0.0006174447326967174\n",
      "epoch:  61  loss:  0.00040499536456528845\n",
      "epoch:  61  loss:  0.0002997690909054562\n",
      "epoch:  61  loss:  2.0927044797688042e-05\n",
      "epoch:  62  loss:  0.0006366005724503621\n",
      "epoch:  62  loss:  4.371131209489349e-05\n",
      "epoch:  62  loss:  5.3839453853914775e-05\n",
      "epoch:  63  loss:  2.826868064704467e-05\n",
      "epoch:  63  loss:  0.0006436991238968719\n",
      "epoch:  63  loss:  6.173598139479054e-05\n",
      "epoch:  64  loss:  2.8957384102018313e-05\n",
      "epoch:  64  loss:  4.7802962977294755e-05\n",
      "epoch:  64  loss:  0.001010486333625228\n",
      "epoch:  65  loss:  2.4544904823731112e-05\n",
      "epoch:  65  loss:  0.0006637594777210579\n",
      "epoch:  65  loss:  2.6453519414454304e-05\n",
      "epoch:  66  loss:  0.0006384406854641754\n",
      "epoch:  66  loss:  4.583860381919718e-05\n",
      "epoch:  66  loss:  2.8749016362196387e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  67  loss:  0.0006528146802839412\n",
      "epoch:  67  loss:  2.4829353370998552e-05\n",
      "epoch:  67  loss:  3.49986938904954e-05\n",
      "epoch:  68  loss:  0.0003842380936589692\n",
      "epoch:  68  loss:  4.151009985328297e-05\n",
      "epoch:  68  loss:  0.0004340539898355443\n",
      "epoch:  69  loss:  0.0004052485342324581\n",
      "epoch:  69  loss:  0.00028088741932097845\n",
      "epoch:  69  loss:  1.2740918812184009e-05\n",
      "epoch:  70  loss:  0.0002718624459954813\n",
      "epoch:  70  loss:  2.992787435176352e-05\n",
      "epoch:  70  loss:  0.000624810281543595\n",
      "epoch:  71  loss:  2.9954883482211375e-05\n",
      "epoch:  71  loss:  0.0006401860227190823\n",
      "epoch:  71  loss:  3.312385423554144e-05\n",
      "epoch:  72  loss:  2.323973079390357e-05\n",
      "epoch:  72  loss:  0.0002760830979535875\n",
      "epoch:  72  loss:  0.0006205507110447396\n",
      "epoch:  73  loss:  0.0006460089651560115\n",
      "epoch:  73  loss:  2.4590086997625395e-05\n",
      "epoch:  73  loss:  2.518226493332697e-05\n",
      "epoch:  74  loss:  0.00038992608375335985\n",
      "epoch:  74  loss:  2.4045993574179183e-05\n",
      "epoch:  74  loss:  0.00043380223318309773\n",
      "epoch:  75  loss:  0.0003982596539633461\n",
      "epoch:  75  loss:  2.8382771649025368e-05\n",
      "epoch:  75  loss:  0.0004083372952547226\n",
      "epoch:  76  loss:  2.8806113420958825e-05\n",
      "epoch:  76  loss:  0.000639016408995799\n",
      "epoch:  76  loss:  1.8429199618501764e-05\n",
      "epoch:  77  loss:  0.0004003474126711168\n",
      "epoch:  77  loss:  0.00025853170888748793\n",
      "epoch:  77  loss:  3.1102948239703305e-05\n",
      "epoch:  78  loss:  0.0002664675814742896\n",
      "epoch:  78  loss:  0.00038652517027748854\n",
      "epoch:  78  loss:  3.9947315639602816e-05\n",
      "epoch:  79  loss:  2.0599910002823286e-05\n",
      "epoch:  79  loss:  0.00027412731067285196\n",
      "epoch:  79  loss:  0.0006103084503279536\n",
      "epoch:  80  loss:  3.243919072337952e-05\n",
      "epoch:  80  loss:  0.0006319677092417495\n",
      "epoch:  80  loss:  1.4346794772767643e-05\n",
      "epoch:  81  loss:  2.117569031713657e-05\n",
      "epoch:  81  loss:  0.0003819561483382846\n",
      "epoch:  81  loss:  0.00043156201684823437\n",
      "epoch:  82  loss:  0.000263147968049532\n",
      "epoch:  82  loss:  0.00039663741189134734\n",
      "epoch:  82  loss:  1.7804122245372375e-05\n",
      "epoch:  83  loss:  1.5635458653229808e-05\n",
      "epoch:  83  loss:  0.0006474237238525676\n",
      "epoch:  83  loss:  8.73924209744805e-06\n",
      "epoch:  84  loss:  2.5939301377588867e-05\n",
      "epoch:  84  loss:  1.53449686733687e-05\n",
      "epoch:  84  loss:  0.0010017420854984314\n",
      "epoch:  85  loss:  2.7607087258625007e-05\n",
      "epoch:  85  loss:  1.0991543606345856e-05\n",
      "epoch:  85  loss:  0.0010034630636990018\n",
      "epoch:  86  loss:  0.0006381096159935313\n",
      "epoch:  86  loss:  1.2752350806318935e-05\n",
      "epoch:  86  loss:  2.211359154764554e-05\n",
      "epoch:  87  loss:  0.00026460621791825535\n",
      "epoch:  87  loss:  0.0003817991370361871\n",
      "epoch:  87  loss:  2.7445152196912255e-05\n",
      "epoch:  88  loss:  2.0184256713501895e-05\n",
      "epoch:  88  loss:  0.000386965503866862\n",
      "epoch:  88  loss:  0.00040850804327976673\n",
      "epoch:  89  loss:  1.6105169742482872e-05\n",
      "epoch:  89  loss:  0.0003873041171246761\n",
      "epoch:  89  loss:  0.0004133061304590952\n",
      "epoch:  90  loss:  0.000261984309675707\n",
      "epoch:  90  loss:  1.7103849903744234e-05\n",
      "epoch:  90  loss:  0.0006103741779924612\n",
      "epoch:  91  loss:  2.6168302356555494e-05\n",
      "epoch:  91  loss:  0.0006274236176329844\n",
      "epoch:  91  loss:  8.591806491277308e-06\n",
      "epoch:  92  loss:  0.00026588751909898377\n",
      "epoch:  92  loss:  0.0003851432130033078\n",
      "epoch:  92  loss:  1.1169385288540456e-05\n",
      "epoch:  93  loss:  2.2260908842290817e-05\n",
      "epoch:  93  loss:  1.2590944005247573e-05\n",
      "epoch:  93  loss:  0.000995849763336565\n",
      "epoch:  94  loss:  0.0003815436410997715\n",
      "epoch:  94  loss:  1.6829116573189623e-05\n",
      "epoch:  94  loss:  0.00041262683129919195\n",
      "epoch:  95  loss:  1.3081294590842862e-05\n",
      "epoch:  95  loss:  0.0006324100521334841\n",
      "epoch:  95  loss:  1.6176806302234244e-05\n",
      "epoch:  96  loss:  0.0006262873488748201\n",
      "epoch:  96  loss:  1.8034360277525516e-05\n",
      "epoch:  96  loss:  1.6591640827160146e-05\n",
      "epoch:  97  loss:  1.5607802453229267e-05\n",
      "epoch:  97  loss:  0.00038674662518097403\n",
      "epoch:  97  loss:  0.0004019701433846484\n",
      "epoch:  98  loss:  0.0006336428825030558\n",
      "epoch:  98  loss:  1.2769551745368726e-05\n",
      "epoch:  98  loss:  9.867714894158617e-06\n",
      "epoch:  99  loss:  0.0003831791587354171\n",
      "epoch:  99  loss:  0.00026070742439140597\n",
      "epoch:  99  loss:  1.2752566961871473e-05\n"
     ]
    }
   ],
   "source": [
    "learning_changed = False\n",
    "for epoch in range(100):\n",
    "    for i_batch, sample_batched in enumerate(dataset_loader):\n",
    "        #print(i_batch, sample_batched['image'].size(),sample_batched['mask'].size())\n",
    "\n",
    "        # Forward Propagation\n",
    "        y_pred = roi.model(sample_batched['image'])\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, sample_batched['mask'])\n",
    "        print('epoch: ', epoch,' loss: ', loss.item())\n",
    "                # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataset_loader):\n",
    "            #print(i_batch, sample_batched['image'].size(),sample_batched['mask'].size())\n",
    "\n",
    "            # Forward Propagation\n",
    "    y_pred = roi.model(sample_batched['image'])\n",
    "            \n",
    "    y_pred = np.reshape(y_pred.detach().numpy()[0], (32,32))\n",
    "    img = Image.fromarray(y_pred, 'L')\n",
    "    img.show()\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
