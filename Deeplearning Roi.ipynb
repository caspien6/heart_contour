{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_raw_data as clean\n",
    "\n",
    "source = 'C:/Users/Ede/Documents/Iskola/onw_hear/root'\n",
    "target = 'C:/Users/Ede/Documents/Iskola/onw_hear/root/cleaned_data'\n",
    "crd = clean.CleanRawData(source, target, 4)\n",
    "crd.create_folder_chunks()\n",
    "print(\"Data were split up to parts. Start multiprocessing.\")\n",
    "lock = clean.Lock()\n",
    "for p in range(crd.thread_num):\n",
    "    fn = crd.clean_data\n",
    "    args = [(lock, crd.new_roots[i], (crd.file_statistic[0][i], crd.file_statistic[1][i])) for i in range(crd.thread_num)]\n",
    "    clean.Process(target=fn, args=(args[p],)).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(n_h, n_out),\n",
    "                     nn.Sigmoid())\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "for epoch in range(50):\n",
    "    # Forward Propagation\n",
    "    y_pred = model(x)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_image('./root/cleaned_data/img_0_22.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import png\n",
    "import pydicom\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roi import RoiLearn\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 1, 64, 64]) torch.Size([1])\n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ..., -0.7086, -0.5740, -0.4688],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.7086, -0.5740, -0.4688],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.7086, -0.5740, -0.4688],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.7086, -0.5740, -0.4688],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.7086, -0.5740, -0.4688],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.7086, -0.5740, -0.4688]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.4531, 0.5228, 0.4867,  ..., 0.5170, 0.4869, 0.5214]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4524, 0.5244, 0.4869,  ..., 0.5176, 0.4867, 0.5232]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4506, 0.5245, 0.4910,  ..., 0.5144, 0.4874, 0.5226]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4504, 0.5215, 0.4870,  ..., 0.5145, 0.4890, 0.5201]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4552, 0.5229, 0.4835,  ..., 0.5167, 0.4915, 0.5205]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4575, 0.5227, 0.4828,  ..., 0.5189, 0.4942, 0.5252]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4565, 0.5213, 0.4826,  ..., 0.5151, 0.4923, 0.5272]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4551, 0.5206, 0.4810,  ..., 0.5183, 0.4916, 0.5261]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4534, 0.5201, 0.4815,  ..., 0.5193, 0.4898, 0.5254]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4535, 0.5206, 0.4814,  ..., 0.5184, 0.4904, 0.5260]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4547, 0.5216, 0.4808,  ..., 0.5205, 0.4908, 0.5259]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4564, 0.5207, 0.4817,  ..., 0.5178, 0.4901, 0.5282]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4536, 0.5241, 0.4816,  ..., 0.5214, 0.4922, 0.5289]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4523, 0.5227, 0.4810,  ..., 0.5209, 0.4922, 0.5277]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4524, 0.5222, 0.4817,  ..., 0.5183, 0.4910, 0.5256]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4509, 0.5231, 0.4823,  ..., 0.5208, 0.4907, 0.5265]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4518, 0.5232, 0.4855,  ..., 0.5177, 0.4882, 0.5258]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4517, 0.5241, 0.4844,  ..., 0.5159, 0.4873, 0.5270]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4526, 0.5230, 0.4862,  ..., 0.5163, 0.4880, 0.5257]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4504, 0.5254, 0.4881,  ..., 0.5175, 0.4906, 0.5215]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4504, 0.5237, 0.4877,  ..., 0.5157, 0.4887, 0.5243]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4502, 0.5221, 0.4865,  ..., 0.5150, 0.4872, 0.5222]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4503, 0.5211, 0.4852,  ..., 0.5176, 0.4876, 0.5192]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4501, 0.5222, 0.4869,  ..., 0.5172, 0.4874, 0.5229]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4506, 0.5216, 0.4850,  ..., 0.5177, 0.4881, 0.5208]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4399, 0.5284, 0.4933,  ..., 0.5167, 0.5011, 0.4903]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4378, 0.5232, 0.4925,  ..., 0.5121, 0.5017, 0.4897]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4370, 0.5249, 0.4961,  ..., 0.5107, 0.4994, 0.4944]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4384, 0.5228, 0.4912,  ..., 0.5134, 0.5010, 0.4870]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4409, 0.5192, 0.4900,  ..., 0.5139, 0.5004, 0.4816]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4456, 0.5188, 0.4850,  ..., 0.5166, 0.5028, 0.4867]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4475, 0.5240, 0.4866,  ..., 0.5170, 0.5035, 0.4888]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4470, 0.5232, 0.4883,  ..., 0.5134, 0.5009, 0.4925]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4488, 0.5197, 0.4899,  ..., 0.5110, 0.4955, 0.4954]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4487, 0.5225, 0.4843,  ..., 0.5148, 0.4979, 0.4923]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4493, 0.5228, 0.4828,  ..., 0.5186, 0.4997, 0.4930]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4501, 0.5197, 0.4810,  ..., 0.5164, 0.4986, 0.4933]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4491, 0.5185, 0.4830,  ..., 0.5176, 0.4996, 0.4915]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4469, 0.5224, 0.4843,  ..., 0.5170, 0.4966, 0.4931]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4464, 0.5210, 0.4838,  ..., 0.5158, 0.4970, 0.4911]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4428, 0.5240, 0.4861,  ..., 0.5191, 0.4992, 0.4895]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4412, 0.5230, 0.4868,  ..., 0.5212, 0.4974, 0.4885]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4393, 0.5262, 0.4895,  ..., 0.5176, 0.4998, 0.4914]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4407, 0.5220, 0.4885,  ..., 0.5169, 0.5005, 0.4900]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4424, 0.5229, 0.4856,  ..., 0.5204, 0.5034, 0.4836]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4398, 0.5261, 0.4908,  ..., 0.5126, 0.4986, 0.4923]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4377, 0.5295, 0.4926,  ..., 0.5126, 0.4977, 0.4902]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4398, 0.5252, 0.4889,  ..., 0.5160, 0.4999, 0.4908]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4416, 0.5230, 0.4883,  ..., 0.5183, 0.5010, 0.4876]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4372, 0.5276, 0.4902,  ..., 0.5164, 0.5016, 0.4888]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4163, 0.5311, 0.4942,  ..., 0.5373, 0.4886, 0.4979]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4162, 0.5298, 0.4974,  ..., 0.5303, 0.4825, 0.5008]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4116, 0.5312, 0.5026,  ..., 0.5354, 0.4794, 0.4986]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4136, 0.5279, 0.4994,  ..., 0.5391, 0.4826, 0.4972]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4191, 0.5276, 0.4944,  ..., 0.5439, 0.4844, 0.4957]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4249, 0.5304, 0.4912,  ..., 0.5436, 0.4829, 0.4971]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4305, 0.5327, 0.4880,  ..., 0.5520, 0.4878, 0.4946]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4301, 0.5282, 0.4872,  ..., 0.5506, 0.4890, 0.4928]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4314, 0.5274, 0.4823,  ..., 0.5488, 0.4866, 0.4940]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4288, 0.5295, 0.4821,  ..., 0.5484, 0.4859, 0.4956]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4312, 0.5295, 0.4824,  ..., 0.5475, 0.4855, 0.4965]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4324, 0.5303, 0.4830,  ..., 0.5500, 0.4879, 0.4945]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4298, 0.5312, 0.4869,  ..., 0.5453, 0.4844, 0.4963]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4294, 0.5273, 0.4835,  ..., 0.5464, 0.4886, 0.4947]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4235, 0.5276, 0.4911,  ..., 0.5433, 0.4849, 0.4934]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4169, 0.5272, 0.4948,  ..., 0.5421, 0.4860, 0.4966]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4117, 0.5298, 0.4960,  ..., 0.5393, 0.4820, 0.4995]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4134, 0.5294, 0.4948,  ..., 0.5417, 0.4847, 0.4969]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4145, 0.5288, 0.4957,  ..., 0.5368, 0.4817, 0.4998]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4138, 0.5271, 0.4959,  ..., 0.5387, 0.4847, 0.4999]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4134, 0.5308, 0.4964,  ..., 0.5368, 0.4851, 0.5010]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4122, 0.5314, 0.4970,  ..., 0.5370, 0.4857, 0.5001]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4138, 0.5314, 0.4974,  ..., 0.5370, 0.4873, 0.4999]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4142, 0.5317, 0.4938,  ..., 0.5368, 0.4861, 0.5012]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4138, 0.5310, 0.4950,  ..., 0.5378, 0.4864, 0.4992]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4181, 0.5315, 0.5180,  ..., 0.5443, 0.4885, 0.5056]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4160, 0.5307, 0.5110,  ..., 0.5448, 0.4959, 0.5038]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4183, 0.5300, 0.5177,  ..., 0.5455, 0.4916, 0.4990]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4180, 0.5288, 0.5168,  ..., 0.5442, 0.4860, 0.4992]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4218, 0.5297, 0.5102,  ..., 0.5506, 0.4911, 0.5044]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4277, 0.5271, 0.5083,  ..., 0.5568, 0.4878, 0.5035]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4308, 0.5250, 0.5027,  ..., 0.5583, 0.4862, 0.4986]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4311, 0.5267, 0.5012,  ..., 0.5544, 0.4857, 0.4945]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4324, 0.5258, 0.4989,  ..., 0.5563, 0.4844, 0.4925]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4345, 0.5278, 0.4981,  ..., 0.5547, 0.4872, 0.4917]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4346, 0.5310, 0.5000,  ..., 0.5562, 0.4903, 0.4904]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4380, 0.5298, 0.4973,  ..., 0.5577, 0.4915, 0.4954]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4351, 0.5304, 0.4964,  ..., 0.5560, 0.4900, 0.4927]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4326, 0.5319, 0.5057,  ..., 0.5547, 0.4913, 0.4934]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4229, 0.5298, 0.5072,  ..., 0.5496, 0.4864, 0.4982]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4205, 0.5287, 0.5128,  ..., 0.5501, 0.4847, 0.5054]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4155, 0.5277, 0.5133,  ..., 0.5477, 0.4863, 0.5050]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4162, 0.5287, 0.5155,  ..., 0.5460, 0.4849, 0.5040]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4179, 0.5300, 0.5132,  ..., 0.5484, 0.4897, 0.5041]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4162, 0.5298, 0.5149,  ..., 0.5475, 0.4859, 0.5022]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4158, 0.5307, 0.5128,  ..., 0.5442, 0.4897, 0.5041]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4131, 0.5300, 0.5155,  ..., 0.5459, 0.4867, 0.5048]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4141, 0.5286, 0.5180,  ..., 0.5460, 0.4883, 0.5070]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4145, 0.5279, 0.5140,  ..., 0.5471, 0.4869, 0.5038]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4161, 0.5278, 0.5155,  ..., 0.5464, 0.4863, 0.5045]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4132, 0.5282, 0.5340,  ..., 0.5571, 0.4740, 0.5303]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4128, 0.5270, 0.5345,  ..., 0.5573, 0.4750, 0.5317]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4183, 0.5239, 0.5351,  ..., 0.5583, 0.4760, 0.5248]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4198, 0.5240, 0.5365,  ..., 0.5588, 0.4782, 0.5276]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4202, 0.5250, 0.5295,  ..., 0.5618, 0.4780, 0.5289]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4217, 0.5274, 0.5267,  ..., 0.5669, 0.4751, 0.5332]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4289, 0.5268, 0.5203,  ..., 0.5739, 0.4710, 0.5290]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4345, 0.5277, 0.5164,  ..., 0.5745, 0.4670, 0.5292]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4391, 0.5305, 0.5140,  ..., 0.5762, 0.4685, 0.5252]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4390, 0.5312, 0.5137,  ..., 0.5737, 0.4709, 0.5273]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4395, 0.5328, 0.5114,  ..., 0.5770, 0.4703, 0.5241]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4405, 0.5317, 0.5109,  ..., 0.5756, 0.4712, 0.5247]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4343, 0.5309, 0.5185,  ..., 0.5736, 0.4700, 0.5246]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4301, 0.5278, 0.5219,  ..., 0.5727, 0.4698, 0.5291]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4235, 0.5282, 0.5261,  ..., 0.5665, 0.4699, 0.5301]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4153, 0.5287, 0.5291,  ..., 0.5611, 0.4698, 0.5302]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4123, 0.5276, 0.5325,  ..., 0.5601, 0.4734, 0.5320]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4120, 0.5298, 0.5337,  ..., 0.5594, 0.4744, 0.5316]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4136, 0.5278, 0.5285,  ..., 0.5589, 0.4769, 0.5339]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4140, 0.5289, 0.5313,  ..., 0.5584, 0.4763, 0.5341]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4126, 0.5287, 0.5328,  ..., 0.5572, 0.4763, 0.5323]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4097, 0.5276, 0.5336,  ..., 0.5548, 0.4784, 0.5319]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4092, 0.5266, 0.5345,  ..., 0.5534, 0.4785, 0.5329]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4116, 0.5275, 0.5340,  ..., 0.5544, 0.4782, 0.5328]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4120, 0.5260, 0.5342,  ..., 0.5566, 0.4781, 0.5312]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4069, 0.5195, 0.5468,  ..., 0.5625, 0.4728, 0.5288]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4106, 0.5204, 0.5457,  ..., 0.5657, 0.4677, 0.5285]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4109, 0.5188, 0.5473,  ..., 0.5616, 0.4702, 0.5248]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4090, 0.5182, 0.5486,  ..., 0.5644, 0.4703, 0.5249]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4078, 0.5209, 0.5499,  ..., 0.5654, 0.4677, 0.5277]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4146, 0.5240, 0.5429,  ..., 0.5716, 0.4704, 0.5301]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4198, 0.5241, 0.5396,  ..., 0.5745, 0.4690, 0.5313]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4232, 0.5254, 0.5366,  ..., 0.5798, 0.4658, 0.5336]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4253, 0.5249, 0.5365,  ..., 0.5830, 0.4636, 0.5341]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4280, 0.5264, 0.5332,  ..., 0.5859, 0.4624, 0.5343]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4272, 0.5266, 0.5295,  ..., 0.5853, 0.4651, 0.5338]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4237, 0.5253, 0.5322,  ..., 0.5816, 0.4647, 0.5309]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4245, 0.5265, 0.5341,  ..., 0.5834, 0.4613, 0.5332]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4220, 0.5276, 0.5377,  ..., 0.5816, 0.4658, 0.5343]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4169, 0.5259, 0.5447,  ..., 0.5772, 0.4651, 0.5342]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4103, 0.5219, 0.5468,  ..., 0.5684, 0.4688, 0.5308]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4045, 0.5195, 0.5479,  ..., 0.5648, 0.4703, 0.5271]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4040, 0.5205, 0.5476,  ..., 0.5640, 0.4712, 0.5279]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4043, 0.5230, 0.5483,  ..., 0.5607, 0.4722, 0.5277]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4079, 0.5249, 0.5476,  ..., 0.5678, 0.4723, 0.5308]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4069, 0.5213, 0.5491,  ..., 0.5615, 0.4737, 0.5282]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4055, 0.5226, 0.5516,  ..., 0.5622, 0.4740, 0.5269]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4040, 0.5230, 0.5520,  ..., 0.5622, 0.4723, 0.5292]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4046, 0.5224, 0.5494,  ..., 0.5595, 0.4760, 0.5270]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4073, 0.5230, 0.5487,  ..., 0.5657, 0.4732, 0.5294]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4010, 0.5083, 0.5504,  ..., 0.5645, 0.4800, 0.5164]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4045, 0.5113, 0.5496,  ..., 0.5718, 0.4810, 0.5176]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4114, 0.5108, 0.5452,  ..., 0.5723, 0.4781, 0.5202]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4099, 0.5131, 0.5467,  ..., 0.5705, 0.4817, 0.5213]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4055, 0.5136, 0.5507,  ..., 0.5644, 0.4843, 0.5224]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4082, 0.5133, 0.5435,  ..., 0.5710, 0.4802, 0.5238]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4096, 0.5149, 0.5433,  ..., 0.5763, 0.4781, 0.5211]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4159, 0.5155, 0.5405,  ..., 0.5838, 0.4758, 0.5255]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4159, 0.5155, 0.5399,  ..., 0.5826, 0.4745, 0.5258]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4170, 0.5161, 0.5380,  ..., 0.5823, 0.4718, 0.5234]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4136, 0.5159, 0.5392,  ..., 0.5806, 0.4729, 0.5221]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4121, 0.5162, 0.5431,  ..., 0.5803, 0.4757, 0.5239]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4140, 0.5163, 0.5408,  ..., 0.5793, 0.4756, 0.5286]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4123, 0.5151, 0.5436,  ..., 0.5745, 0.4794, 0.5257]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4106, 0.5136, 0.5487,  ..., 0.5729, 0.4800, 0.5230]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4073, 0.5135, 0.5504,  ..., 0.5722, 0.4785, 0.5206]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4060, 0.5108, 0.5483,  ..., 0.5698, 0.4811, 0.5172]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4078, 0.5107, 0.5495,  ..., 0.5720, 0.4821, 0.5167]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4041, 0.5090, 0.5479,  ..., 0.5658, 0.4842, 0.5149]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4033, 0.5128, 0.5501,  ..., 0.5695, 0.4794, 0.5158]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4011, 0.5120, 0.5526,  ..., 0.5671, 0.4800, 0.5164]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3992, 0.5088, 0.5518,  ..., 0.5673, 0.4808, 0.5133]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4032, 0.5106, 0.5525,  ..., 0.5677, 0.4808, 0.5147]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4010, 0.5097, 0.5486,  ..., 0.5663, 0.4810, 0.5136]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4044, 0.5094, 0.5489,  ..., 0.5624, 0.4822, 0.5161]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4100, 0.4979, 0.5613,  ..., 0.5483, 0.5013, 0.5033]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4096, 0.5013, 0.5627,  ..., 0.5509, 0.5017, 0.5045]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4133, 0.4993, 0.5565,  ..., 0.5594, 0.4990, 0.5103]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4124, 0.5024, 0.5577,  ..., 0.5629, 0.4987, 0.5124]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4111, 0.5053, 0.5598,  ..., 0.5568, 0.5014, 0.5110]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4121, 0.5043, 0.5567,  ..., 0.5569, 0.4963, 0.5095]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4158, 0.5059, 0.5524,  ..., 0.5590, 0.4954, 0.5122]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4165, 0.5066, 0.5504,  ..., 0.5605, 0.4946, 0.5127]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4155, 0.5050, 0.5487,  ..., 0.5620, 0.4907, 0.5117]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4180, 0.5056, 0.5497,  ..., 0.5602, 0.4901, 0.5137]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4157, 0.5043, 0.5508,  ..., 0.5548, 0.4956, 0.5142]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4145, 0.5028, 0.5493,  ..., 0.5530, 0.4959, 0.5143]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4115, 0.5026, 0.5526,  ..., 0.5536, 0.4988, 0.5153]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4116, 0.5017, 0.5574,  ..., 0.5552, 0.4950, 0.5112]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4122, 0.5015, 0.5604,  ..., 0.5539, 0.5036, 0.5095]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4132, 0.4985, 0.5569,  ..., 0.5551, 0.4963, 0.5068]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4099, 0.4954, 0.5573,  ..., 0.5493, 0.4980, 0.5039]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4081, 0.4997, 0.5589,  ..., 0.5538, 0.4986, 0.5051]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4124, 0.4988, 0.5596,  ..., 0.5524, 0.5007, 0.5045]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4106, 0.4972, 0.5626,  ..., 0.5483, 0.5018, 0.5029]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4096, 0.4983, 0.5621,  ..., 0.5489, 0.5023, 0.5037]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4096, 0.4972, 0.5614,  ..., 0.5457, 0.5052, 0.5035]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4085, 0.4979, 0.5610,  ..., 0.5477, 0.5029, 0.5025]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4084, 0.4971, 0.5604,  ..., 0.5478, 0.5029, 0.5032]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4103, 0.4971, 0.5598,  ..., 0.5523, 0.4987, 0.5036]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4304, 0.4829, 0.5822,  ..., 0.5080, 0.5158, 0.4910]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4320, 0.4833, 0.5811,  ..., 0.5082, 0.5137, 0.4925]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4304, 0.4835, 0.5783,  ..., 0.5147, 0.5133, 0.4934]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4334, 0.4890, 0.5766,  ..., 0.5127, 0.5180, 0.4942]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4338, 0.4874, 0.5770,  ..., 0.5098, 0.5181, 0.4939]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4345, 0.4876, 0.5725,  ..., 0.5098, 0.5140, 0.4950]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4373, 0.4895, 0.5700,  ..., 0.5101, 0.5112, 0.4996]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4415, 0.4889, 0.5641,  ..., 0.5080, 0.5103, 0.5010]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4438, 0.4918, 0.5623,  ..., 0.5147, 0.5107, 0.5023]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4464, 0.4902, 0.5650,  ..., 0.5116, 0.5144, 0.5024]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4441, 0.4897, 0.5668,  ..., 0.5096, 0.5152, 0.5024]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4461, 0.4909, 0.5672,  ..., 0.5135, 0.5144, 0.5034]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4417, 0.4904, 0.5670,  ..., 0.5128, 0.5140, 0.5019]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4422, 0.4926, 0.5706,  ..., 0.5114, 0.5147, 0.5042]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4373, 0.4929, 0.5770,  ..., 0.5106, 0.5133, 0.5012]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4354, 0.4896, 0.5782,  ..., 0.5116, 0.5149, 0.5005]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4316, 0.4874, 0.5769,  ..., 0.5084, 0.5107, 0.4925]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4318, 0.4839, 0.5797,  ..., 0.5043, 0.5162, 0.4961]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4325, 0.4828, 0.5801,  ..., 0.5023, 0.5150, 0.4949]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4318, 0.4836, 0.5801,  ..., 0.5037, 0.5120, 0.4912]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4293, 0.4838, 0.5825,  ..., 0.5038, 0.5125, 0.4902]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4261, 0.4861, 0.5804,  ..., 0.5057, 0.5088, 0.4918]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4297, 0.4818, 0.5802,  ..., 0.5025, 0.5140, 0.4928]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4303, 0.4831, 0.5808,  ..., 0.5050, 0.5142, 0.4939]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4302, 0.4820, 0.5794,  ..., 0.5035, 0.5130, 0.4946]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4416, 0.4774, 0.5729,  ..., 0.4888, 0.5429, 0.4843]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4439, 0.4818, 0.5740,  ..., 0.4981, 0.5401, 0.4854]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4459, 0.4824, 0.5722,  ..., 0.4981, 0.5431, 0.4859]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4446, 0.4794, 0.5690,  ..., 0.4931, 0.5406, 0.4838]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4447, 0.4791, 0.5672,  ..., 0.4912, 0.5436, 0.4856]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4473, 0.4830, 0.5635,  ..., 0.4937, 0.5367, 0.4879]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4499, 0.4842, 0.5598,  ..., 0.5000, 0.5388, 0.4916]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4510, 0.4846, 0.5587,  ..., 0.4985, 0.5381, 0.4927]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4532, 0.4858, 0.5584,  ..., 0.4994, 0.5416, 0.4930]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4544, 0.4869, 0.5565,  ..., 0.5010, 0.5410, 0.4923]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4544, 0.4844, 0.5558,  ..., 0.4990, 0.5405, 0.4918]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4540, 0.4870, 0.5570,  ..., 0.4991, 0.5421, 0.4914]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4540, 0.4848, 0.5634,  ..., 0.4980, 0.5412, 0.4915]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4501, 0.4817, 0.5628,  ..., 0.4949, 0.5410, 0.4922]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4492, 0.4790, 0.5639,  ..., 0.4937, 0.5410, 0.4908]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4444, 0.4751, 0.5627,  ..., 0.4896, 0.5412, 0.4884]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4426, 0.4778, 0.5651,  ..., 0.4925, 0.5442, 0.4892]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4422, 0.4783, 0.5685,  ..., 0.4924, 0.5440, 0.4878]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4403, 0.4766, 0.5681,  ..., 0.4912, 0.5435, 0.4884]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4420, 0.4781, 0.5700,  ..., 0.4932, 0.5422, 0.4846]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4387, 0.4783, 0.5732,  ..., 0.4909, 0.5414, 0.4832]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4407, 0.4781, 0.5741,  ..., 0.4908, 0.5378, 0.4868]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4392, 0.4792, 0.5752,  ..., 0.4929, 0.5370, 0.4810]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4402, 0.4772, 0.5742,  ..., 0.4892, 0.5434, 0.4846]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4418, 0.4784, 0.5738,  ..., 0.4920, 0.5465, 0.4854]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4337, 0.4784, 0.5767,  ..., 0.4741, 0.5545, 0.5128]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4346, 0.4781, 0.5777,  ..., 0.4767, 0.5515, 0.5087]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4354, 0.4789, 0.5821,  ..., 0.4777, 0.5539, 0.5121]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4361, 0.4798, 0.5811,  ..., 0.4735, 0.5534, 0.5143]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4368, 0.4834, 0.5768,  ..., 0.4776, 0.5565, 0.5139]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4343, 0.4846, 0.5782,  ..., 0.4757, 0.5598, 0.5155]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4355, 0.4870, 0.5779,  ..., 0.4812, 0.5641, 0.5194]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4361, 0.4854, 0.5761,  ..., 0.4816, 0.5632, 0.5184]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4335, 0.4859, 0.5768,  ..., 0.4820, 0.5604, 0.5174]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4345, 0.4854, 0.5758,  ..., 0.4825, 0.5581, 0.5157]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4330, 0.4863, 0.5776,  ..., 0.4786, 0.5581, 0.5148]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4329, 0.4865, 0.5790,  ..., 0.4791, 0.5593, 0.5167]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4309, 0.4821, 0.5753,  ..., 0.4803, 0.5558, 0.5172]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4350, 0.4829, 0.5751,  ..., 0.4790, 0.5529, 0.5131]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4385, 0.4848, 0.5790,  ..., 0.4820, 0.5551, 0.5144]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4409, 0.4835, 0.5763,  ..., 0.4820, 0.5545, 0.5138]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4371, 0.4845, 0.5755,  ..., 0.4821, 0.5502, 0.5123]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4331, 0.4812, 0.5738,  ..., 0.4793, 0.5504, 0.5139]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4332, 0.4812, 0.5797,  ..., 0.4745, 0.5513, 0.5156]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4296, 0.4815, 0.5811,  ..., 0.4756, 0.5549, 0.5128]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4282, 0.4822, 0.5815,  ..., 0.4744, 0.5509, 0.5104]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4294, 0.4802, 0.5791,  ..., 0.4703, 0.5541, 0.5100]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4310, 0.4807, 0.5763,  ..., 0.4706, 0.5540, 0.5115]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4297, 0.4808, 0.5766,  ..., 0.4732, 0.5526, 0.5139]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4310, 0.4814, 0.5783,  ..., 0.4755, 0.5518, 0.5120]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4305, 0.4775, 0.5741,  ..., 0.4641, 0.5473, 0.5058]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4313, 0.4820, 0.5768,  ..., 0.4661, 0.5453, 0.5086]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4285, 0.4851, 0.5807,  ..., 0.4704, 0.5455, 0.5141]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4239, 0.4862, 0.5826,  ..., 0.4699, 0.5471, 0.5159]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4210, 0.4854, 0.5840,  ..., 0.4612, 0.5451, 0.5091]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4217, 0.4881, 0.5833,  ..., 0.4624, 0.5439, 0.5097]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4225, 0.4894, 0.5814,  ..., 0.4644, 0.5468, 0.5111]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4232, 0.4896, 0.5793,  ..., 0.4657, 0.5435, 0.5120]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4246, 0.4900, 0.5767,  ..., 0.4675, 0.5438, 0.5099]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4247, 0.4886, 0.5777,  ..., 0.4698, 0.5473, 0.5092]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4232, 0.4887, 0.5757,  ..., 0.4668, 0.5438, 0.5061]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4239, 0.4884, 0.5779,  ..., 0.4663, 0.5427, 0.5032]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4231, 0.4897, 0.5803,  ..., 0.4640, 0.5445, 0.5075]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4246, 0.4866, 0.5815,  ..., 0.4667, 0.5472, 0.5076]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4267, 0.4853, 0.5793,  ..., 0.4676, 0.5496, 0.5114]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4276, 0.4837, 0.5781,  ..., 0.4703, 0.5484, 0.5111]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4301, 0.4830, 0.5752,  ..., 0.4742, 0.5537, 0.5105]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4303, 0.4819, 0.5747,  ..., 0.4721, 0.5573, 0.5059]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4294, 0.4846, 0.5766,  ..., 0.4718, 0.5543, 0.5112]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4299, 0.4836, 0.5767,  ..., 0.4706, 0.5501, 0.5126]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4315, 0.4834, 0.5728,  ..., 0.4688, 0.5498, 0.5094]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4324, 0.4828, 0.5749,  ..., 0.4663, 0.5453, 0.5092]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4326, 0.4824, 0.5745,  ..., 0.4669, 0.5451, 0.5085]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4344, 0.4827, 0.5732,  ..., 0.4665, 0.5479, 0.5083]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4311, 0.4814, 0.5726,  ..., 0.4662, 0.5478, 0.5075]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4119, 0.4684, 0.5965,  ..., 0.4609, 0.5840, 0.5140]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4083, 0.4678, 0.5987,  ..., 0.4586, 0.5852, 0.5106]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4097, 0.4681, 0.6000,  ..., 0.4609, 0.5858, 0.5117]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4109, 0.4726, 0.6004,  ..., 0.4622, 0.5841, 0.5170]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4110, 0.4742, 0.6003,  ..., 0.4585, 0.5863, 0.5165]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4137, 0.4736, 0.6017,  ..., 0.4574, 0.5914, 0.5145]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4130, 0.4743, 0.6006,  ..., 0.4564, 0.5903, 0.5141]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4138, 0.4768, 0.6021,  ..., 0.4572, 0.5879, 0.5121]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4116, 0.4714, 0.6002,  ..., 0.4577, 0.5870, 0.5112]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4125, 0.4711, 0.6009,  ..., 0.4562, 0.5865, 0.5115]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4138, 0.4693, 0.6012,  ..., 0.4563, 0.5897, 0.5086]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4159, 0.4728, 0.6002,  ..., 0.4566, 0.5888, 0.5119]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4138, 0.4719, 0.5991,  ..., 0.4602, 0.5897, 0.5110]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4157, 0.4724, 0.5998,  ..., 0.4625, 0.5860, 0.5124]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4153, 0.4739, 0.5973,  ..., 0.4645, 0.5875, 0.5071]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4148, 0.4737, 0.5967,  ..., 0.4665, 0.5911, 0.5094]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4136, 0.4762, 0.5956,  ..., 0.4682, 0.5891, 0.5110]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4140, 0.4780, 0.5919,  ..., 0.4654, 0.5833, 0.5143]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4110, 0.4738, 0.5952,  ..., 0.4608, 0.5865, 0.5084]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4150, 0.4695, 0.5972,  ..., 0.4616, 0.5890, 0.5077]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4145, 0.4720, 0.5947,  ..., 0.4666, 0.5871, 0.5119]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4139, 0.4722, 0.5957,  ..., 0.4622, 0.5848, 0.5113]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4126, 0.4718, 0.5925,  ..., 0.4607, 0.5864, 0.5083]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4116, 0.4695, 0.5902,  ..., 0.4589, 0.5904, 0.5119]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4122, 0.4671, 0.5928,  ..., 0.4593, 0.5881, 0.5103]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4274, 0.4708, 0.5938,  ..., 0.4449, 0.5797, 0.4904]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4294, 0.4645, 0.5929,  ..., 0.4496, 0.5806, 0.4922]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4269, 0.4657, 0.5944,  ..., 0.4498, 0.5809, 0.4955]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4253, 0.4692, 0.5921,  ..., 0.4421, 0.5773, 0.4982]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4241, 0.4672, 0.5958,  ..., 0.4432, 0.5791, 0.5007]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4259, 0.4688, 0.5964,  ..., 0.4434, 0.5812, 0.4975]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4282, 0.4725, 0.5918,  ..., 0.4425, 0.5801, 0.4960]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4288, 0.4722, 0.5928,  ..., 0.4431, 0.5811, 0.4976]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4307, 0.4715, 0.5916,  ..., 0.4449, 0.5769, 0.5014]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4313, 0.4700, 0.5942,  ..., 0.4406, 0.5755, 0.4984]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4311, 0.4689, 0.5892,  ..., 0.4373, 0.5759, 0.5007]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4293, 0.4688, 0.5940,  ..., 0.4402, 0.5757, 0.5030]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4288, 0.4657, 0.5913,  ..., 0.4380, 0.5762, 0.4980]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4276, 0.4724, 0.5948,  ..., 0.4434, 0.5751, 0.4983]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4302, 0.4726, 0.5940,  ..., 0.4421, 0.5779, 0.4942]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4276, 0.4698, 0.5926,  ..., 0.4449, 0.5815, 0.4931]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4289, 0.4717, 0.5913,  ..., 0.4450, 0.5819, 0.4954]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4263, 0.4756, 0.5937,  ..., 0.4504, 0.5798, 0.4953]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4279, 0.4710, 0.5938,  ..., 0.4481, 0.5804, 0.4934]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4288, 0.4695, 0.5891,  ..., 0.4457, 0.5764, 0.4911]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4287, 0.4695, 0.5863,  ..., 0.4446, 0.5775, 0.4910]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4296, 0.4664, 0.5808,  ..., 0.4434, 0.5787, 0.4932]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4302, 0.4671, 0.5837,  ..., 0.4423, 0.5808, 0.4920]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4252, 0.4655, 0.5860,  ..., 0.4446, 0.5846, 0.4948]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4259, 0.4707, 0.5920,  ..., 0.4467, 0.5796, 0.4921]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4351, 0.4793, 0.5674,  ..., 0.4575, 0.5630, 0.4884]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4354, 0.4814, 0.5691,  ..., 0.4548, 0.5632, 0.4869]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4362, 0.4790, 0.5697,  ..., 0.4524, 0.5594, 0.4906]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4371, 0.4816, 0.5710,  ..., 0.4564, 0.5595, 0.4963]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4361, 0.4781, 0.5685,  ..., 0.4598, 0.5690, 0.4962]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4378, 0.4790, 0.5640,  ..., 0.4596, 0.5640, 0.4920]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4373, 0.4770, 0.5595,  ..., 0.4578, 0.5677, 0.4952]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4389, 0.4793, 0.5586,  ..., 0.4562, 0.5693, 0.4994]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4397, 0.4788, 0.5591,  ..., 0.4563, 0.5696, 0.4980]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4387, 0.4769, 0.5603,  ..., 0.4572, 0.5711, 0.4982]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4395, 0.4785, 0.5645,  ..., 0.4560, 0.5694, 0.4957]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4383, 0.4774, 0.5613,  ..., 0.4569, 0.5674, 0.4977]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4382, 0.4741, 0.5622,  ..., 0.4527, 0.5635, 0.4914]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4373, 0.4770, 0.5623,  ..., 0.4539, 0.5644, 0.4937]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4346, 0.4775, 0.5670,  ..., 0.4554, 0.5647, 0.4919]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4383, 0.4806, 0.5679,  ..., 0.4518, 0.5652, 0.4895]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4408, 0.4789, 0.5695,  ..., 0.4539, 0.5667, 0.4871]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4417, 0.4785, 0.5671,  ..., 0.4549, 0.5668, 0.4881]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4424, 0.4787, 0.5684,  ..., 0.4553, 0.5683, 0.4866]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4410, 0.4778, 0.5645,  ..., 0.4603, 0.5688, 0.4896]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4413, 0.4765, 0.5650,  ..., 0.4606, 0.5682, 0.4875]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4411, 0.4767, 0.5648,  ..., 0.4609, 0.5667, 0.4901]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4440, 0.4775, 0.5658,  ..., 0.4615, 0.5649, 0.4868]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4409, 0.4772, 0.5663,  ..., 0.4597, 0.5651, 0.4886]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4393, 0.4765, 0.5673,  ..., 0.4539, 0.5641, 0.4821]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "roii = RoiLearn()\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "dataLoader = preprocessor.create_datasetLoaderDCM('./root')\n",
    "preprocessor.show_some_loadedData()\n",
    "\n",
    "roii.build_model()\n",
    "\n",
    "roii.propagate_from_dataLoader(dataLoader)\n",
    "#y_pred = roi.propagate().detach().numpy()\n",
    "#save_image(y_pred[0,0,:,:]*255, 'pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class RoiLearn:\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(12)\n",
    "        self.conv1 = nn.Conv2d(1,100, (11,11))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d(6)\n",
    "        self.flatten = Flatten()\n",
    "        self.full = nn.Linear(8100,1024)\n",
    "            \n",
    "    def build_model(self):\n",
    "        self.model = nn.Sequential(self.conv1,\n",
    "                            self.avgpool,\n",
    "                            self.relu,\n",
    "                            self.flatten,\n",
    "                            self.full,\n",
    "                            self.sigmoid\n",
    "                            )\n",
    "        self.model = self.model.double()\n",
    "    \n",
    "    def propagate_from_dataLoader(self,dl):\n",
    "        for i_batch, sample_batched in enumerate(dl):\n",
    "            print(self.model(sample_batched[0]))\n",
    "        \n",
    "    def propagate(self):\n",
    "        return self.model(self.x)\n",
    "    \n",
    "    def save_image( self,npdata, outfilename ) :\n",
    "        img = Image.fromarray( np.asarray( np.clip(npdata,0,255), dtype=\"uint8\"), \"L\" )\n",
    "        img.save( outfilename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pydicom as dicom\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torchvision.datasets as ds\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def preprocess_img(self,img):\n",
    "        img = img.resize((64,64),Image.ANTIALIAS)\n",
    "        img = img.convert('LA')\n",
    "        data = np.asarray( img, dtype=\"float\" )[:,:,:1]\n",
    "        data = np.swapaxes(data, 0, 2)\n",
    "        data[0] = self.scaler.fit_transform(data[0])\n",
    "        return data\n",
    "    \n",
    "    def preprocess_dcm(self,img):\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((64,64),Image.ANTIALIAS)\n",
    "        img = img.convert('LA')\n",
    "        data = np.asarray( img, dtype=\"float\" )[:,:,:1]\n",
    "        #channel - height swap\n",
    "        data = np.swapaxes(data, 0, 2)\n",
    "        data = np.swapaxes(data, 1, 2)\n",
    "        data[0] = self.scaler.fit_transform(data[0])\n",
    "        return data\n",
    "    \n",
    "    def load_image(self, infilename ):\n",
    "        img = Image.open( infilename )\n",
    "        img.load()\n",
    "        return img\n",
    "    \n",
    "    def load_dcm(self,infilename):\n",
    "        temp_ds = dicom.dcmread(infilename).pixel_array\n",
    "        return temp_ds\n",
    "    \n",
    "    def create_datasetLoaderPNG(self, folder):\n",
    "        dataset = ds.DatasetFolder(folder, self.load_image, ['.png'], self.preprocess_img)\n",
    "        self.data = torch.utils.data.DataLoader(dataset)\n",
    "        return self.data\n",
    "    \n",
    "    def create_datasetLoaderDCM(self, folder):\n",
    "        dataset = ds.DatasetFolder(folder, self.load_dcm, ['.dcm'], self.preprocess_dcm)\n",
    "        self.data = torch.utils.data.DataLoader(dataset)\n",
    "        return self.data\n",
    "    \n",
    "    def get_dataLoader(self):\n",
    "        return self.data\n",
    "    \n",
    "    def show_some_loadedData(self):\n",
    "        if (self.data == None):\n",
    "            return\n",
    "        for i_batch, sample_batched in enumerate(self.data):\n",
    "            print(i_batch, sample_batched[0].size(),sample_batched[1].size())\n",
    "            print(sample_batched[0])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
